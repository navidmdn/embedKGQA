{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "DATA_BASE_PATH = './data'\n",
    "KB_PATH = './data/kb.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KB embdedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kb data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KBManager:\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.entity_map = {}\n",
    "        self.relation_map = {}\n",
    "        self._build_vocabs()\n",
    "        \n",
    "    @staticmethod\n",
    "    def extend_vocab(word, vocab):\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab)\n",
    "    \n",
    "    def _build_vocabs(self):\n",
    "        with open(self.data_dir, 'r') as f:\n",
    "            data = f.read()\n",
    "            lines = data.strip().split('\\n')\n",
    "            for line in lines:\n",
    "                subj, rel, obj = line.split('|')\n",
    "                self.extend_vocab(subj, self.entity_map)\n",
    "                self.extend_vocab(obj, self.entity_map)\n",
    "                self.extend_vocab(rel, self.relation_map)\n",
    "    \n",
    "    \n",
    "    def load_er_vocab(self):\n",
    "        result = {}\n",
    "        with open(self.data_dir, 'r') as f:\n",
    "            data = f.read()\n",
    "            lines = data.strip().split('\\n')\n",
    "            for line in lines:\n",
    "                subj, rel, obj = line.split('|')\n",
    "                subj_idx = self.entity_map[subj]\n",
    "                rel_idx = self.relation_map[rel]\n",
    "                obj_idx = self.entity_map[obj]\n",
    "                \n",
    "                er_tuple = (subj_idx, rel_idx)\n",
    "                if er_tuple in result:\n",
    "                    result[er_tuple].append(obj_idx)\n",
    "                else:\n",
    "                    result[er_tuple] = [obj_idx]\n",
    "        return result\n",
    "                \n",
    "    \n",
    "\n",
    "kb_mgr = KBManager(KB_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"kbg_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      multiple                  22135808  \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      multiple                  4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch multiple                  8         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch multiple                  1024      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 22,141,448\n",
      "Trainable params: 22,140,932\n",
      "Non-trainable params: 516\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 512\n",
    "\n",
    "class KBGModel(keras.Model):\n",
    "    \n",
    "    def __init__(self, entity_dim, relation_dim, hidden_dim):\n",
    "        super(KBGModel, self).__init__()\n",
    "    \n",
    "        self.entity_dim = entity_dim\n",
    "        self.relation_dim = relation_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.entity_encoder = keras.layers.Embedding(\n",
    "            self.entity_dim,\n",
    "            self.hidden_dim,\n",
    "            embeddings_regularizer=keras.regularizers.l2(0.1)\n",
    "        )\n",
    "        \n",
    "        self.relation_encoder = keras.layers.Embedding(\n",
    "            self.relation_dim,\n",
    "            self.hidden_dim,\n",
    "            input_shape=(),\n",
    "        )\n",
    "        \n",
    "        self.head_bn = keras.layers.BatchNormalization()\n",
    "        self.head_drpout = keras.layers.Dropout(0.3)\n",
    "        self.rel_drpout = keras.layers.Dropout(0.4)\n",
    "        self.score_bn = keras.layers.BatchNormalization()\n",
    "        self.output_drpout = keras.layers.Dropout(0.5)\n",
    "        \n",
    "    def get_score(self, head, relation, entity_encoder):\n",
    "        \n",
    "        assert self.hidden_dim % 2 == 0\n",
    "        hidden_dim_slice = int(self.hidden_dim/2)\n",
    "\n",
    "        head_norm = self.head_bn(tf.reshape(head, (-1, hidden_dim_slice, 2)))\n",
    "        head_drp = self.head_drpout(head_norm)\n",
    "\n",
    "        head_drp = tf.reshape(head_drp, (-1, self.hidden_dim))\n",
    "\n",
    "        re_head = tf.slice(head_drp, [0, 0], [-1, hidden_dim_slice])\n",
    "        im_head = tf.slice(head_drp, [0, hidden_dim_slice], [-1, -1])\n",
    "\n",
    "        relation_drp = self.rel_drpout(tf.squeeze(relation))\n",
    "        re_relation = tf.slice(relation_drp, [0, 0], [-1, hidden_dim_slice])\n",
    "        im_relation = tf.slice(relation_drp, [0, hidden_dim_slice], [-1, -1])\n",
    "\n",
    "        re_tail = tf.slice(tf.squeeze(entity_encoder.weights), [0, 0], [-1, hidden_dim_slice])\n",
    "        im_tail = tf.slice(tf.squeeze(entity_encoder.weights), [0, hidden_dim_slice], [-1, -1])\n",
    "\n",
    "        re_score = re_head * re_relation - im_head * im_relation\n",
    "        im_score = re_head * im_relation + im_head * re_relation\n",
    "\n",
    "        score = tf.stack([re_score, im_score], axis=1)\n",
    "        score_bn = self.score_bn(score)\n",
    "        score_drp = self.output_drpout(score_bn)\n",
    "\n",
    "        score_drp = tf.reshape(score_drp, (-1, self.hidden_dim))\n",
    "        re_score = tf.slice(score_drp, [0, 0], [-1, hidden_dim_slice])\n",
    "        im_score = tf.slice(score_drp, [0, hidden_dim_slice], [-1, -1])\n",
    "\n",
    "        scores = tf.add(\n",
    "            tf.matmul(re_score, re_tail, transpose_b=True),\n",
    "            tf.matmul(im_score, im_tail, transpose_b=True)\n",
    "        )\n",
    "\n",
    "        return scores\n",
    "        \n",
    "    def call(self, subj_ids, rel_ids):\n",
    "        entity_embedding = self.entity_encoder(subj_ids)\n",
    "        rel_embedding = self.relation_encoder(rel_ids)\n",
    "        \n",
    "        scores = self.get_score(entity_embedding, rel_embedding, self.entity_encoder)\n",
    "        prediction = tf.sigmoid(scores)\n",
    "        \n",
    "        return prediction\n",
    "\n",
    "entity_dim = len(kb_mgr.entity_map)\n",
    "relation_dim = len(kb_mgr.relation_map)\n",
    "kg_model = KBGModel(entity_dim, relation_dim, EMBEDDING_DIM)\n",
    "\n",
    "kg_model.load_weights('data/complex/saved_models/complex')\n",
    "\n",
    "kg_model(\n",
    "    np.array([425, 77]),\n",
    "    np.array([1,2]),\n",
    "    training=False\n",
    ")\n",
    "\n",
    "kg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Kismet': 0,\n",
       " 'William Dieterle': 1,\n",
       " 'Edward Knoblock': 2,\n",
       " 'Marlene Dietrich': 3,\n",
       " 'Edward Arnold': 4,\n",
       " 'Ronald Colman': 5,\n",
       " 'James Craig': 6,\n",
       " '1944': 7,\n",
       " 'English': 8,\n",
       " 'bd-r': 9,\n",
       " 'Flags of Our Fathers': 10,\n",
       " 'Clint Eastwood': 11,\n",
       " 'Paul Haggis': 12,\n",
       " 'Ron Powers': 13,\n",
       " 'James Bradley': 14,\n",
       " '2006': 15,\n",
       " 'War': 16,\n",
       " 'famous': 17,\n",
       " 'world war ii': 18,\n",
       " 'war': 19,\n",
       " 'r': 20,\n",
       " 'clint eastwood': 21,\n",
       " 'american': 22,\n",
       " 'iwo jima': 23,\n",
       " 'flag': 24,\n",
       " 'The Bride Wore Black': 25,\n",
       " 'François Truffaut': 26,\n",
       " 'Cornell Woolrich': 27,\n",
       " 'Jeanne Moreau': 28,\n",
       " 'Michel Bouquet': 29,\n",
       " 'Charles Denner': 30,\n",
       " '1968': 31,\n",
       " 'French': 32,\n",
       " 'revenge': 33,\n",
       " 'wedding': 34,\n",
       " 'françois truffaut': 35,\n",
       " 'black': 36,\n",
       " 'bride': 37,\n",
       " 'Dirty Filthy Love': 38,\n",
       " 'Adrian Shergold': 39,\n",
       " 'Jeff Pope': 40,\n",
       " 'Michael Sheen': 41,\n",
       " 'Claudie Blakley': 42,\n",
       " 'Anastasia Griffith': 43,\n",
       " 'Adrian Bower': 44,\n",
       " '2004': 45,\n",
       " 'Drama': 46,\n",
       " 'The Dark Horse': 47,\n",
       " 'Alfred E. Green': 48,\n",
       " 'Bette Davis': 49,\n",
       " 'Warren William': 50,\n",
       " '1932': 51,\n",
       " 'Comedy': 52,\n",
       " 'alfred e. green': 53,\n",
       " 'The Sentinel': 54,\n",
       " 'Clark Johnson': 55,\n",
       " 'Gerald Petievich': 56,\n",
       " 'Michael Douglas': 57,\n",
       " 'Kiefer Sutherland': 58,\n",
       " 'Eva Longoria': 59,\n",
       " 'Thriller': 60,\n",
       " 'Crime': 61,\n",
       " 'thriller': 62,\n",
       " 'crime': 63,\n",
       " 'michael douglas': 64,\n",
       " 'secret service': 65,\n",
       " 'Funny About Love': 66,\n",
       " 'Leonard Nimoy': 67,\n",
       " 'Norman Steinberg': 68,\n",
       " 'David Frankel': 69,\n",
       " 'Bob Greene': 70,\n",
       " 'Gene Wilder': 71,\n",
       " '1990': 72,\n",
       " 'Kissed': 73,\n",
       " 'Lynne Stopkewich': 74,\n",
       " 'Barbara Gowdy': 75,\n",
       " 'Molly Parker': 76,\n",
       " 'Peter Outerbridge': 77,\n",
       " '1996': 78,\n",
       " 'necrophilia': 79,\n",
       " 'Alive': 80,\n",
       " 'Tsutomu Takahashi': 81,\n",
       " 'Hideo Sakaki': 82,\n",
       " '2002': 83,\n",
       " 'Japanese': 84,\n",
       " 'Action': 85,\n",
       " 'japan': 86,\n",
       " 'prison': 87,\n",
       " 'Snow Queen': 88,\n",
       " 'David Wu': 89,\n",
       " 'Bridget Fonda': 90,\n",
       " 'Chelsea Hobbs': 91,\n",
       " 'Chopper': 92,\n",
       " 'Andrew Dominik': 93,\n",
       " 'Eric Bana': 94,\n",
       " 'David Field': 95,\n",
       " 'Simon Lyndon': 96,\n",
       " '2000': 97,\n",
       " 'australia': 98,\n",
       " 'australian': 99,\n",
       " 'eric bana': 100,\n",
       " 'andrew dominik': 101,\n",
       " 'The Mistress of Spices': 102,\n",
       " 'Paul Mayeda Berges': 103,\n",
       " 'Gurinder Chadha': 104,\n",
       " 'Chitra Banerjee Divakaruni': 105,\n",
       " '2005': 106,\n",
       " 'Snow Dogs': 107,\n",
       " 'Brian Levant': 108,\n",
       " 'Gary Paulsen': 109,\n",
       " 'James Coburn': 110,\n",
       " 'brian levant': 111,\n",
       " 'House': 112,\n",
       " 'Steve Miner': 113,\n",
       " 'William Katt': 114,\n",
       " 'George Wendt': 115,\n",
       " 'Kay Lenz': 116,\n",
       " 'Richard Moll': 117,\n",
       " '1986': 118,\n",
       " 'Horror': 119,\n",
       " 'The Hidden Fortress': 120,\n",
       " 'Akira Kurosawa': 121,\n",
       " '1958': 122,\n",
       " 'akira kurosawa': 123,\n",
       " 'toshiro mifune': 124,\n",
       " 'kurosawa': 125,\n",
       " 'princess': 126,\n",
       " 'I Want to Live!': 127,\n",
       " 'Robert Wise': 128,\n",
       " 'Nelson Gidding': 129,\n",
       " 'Don Mankiewicz': 130,\n",
       " 'Barbara Graham': 131,\n",
       " 'Ed Montgomery': 132,\n",
       " 'Susan Hayward': 133,\n",
       " 'Theodore Bikel': 134,\n",
       " 'Simon Oakland': 135,\n",
       " 'murder': 136,\n",
       " 'robert wise': 137,\n",
       " 'Mrs. Parkington': 138,\n",
       " 'Tay Garnett': 139,\n",
       " 'Robert Thoeren': 140,\n",
       " 'Louis Bromfield': 141,\n",
       " 'Polly James': 142,\n",
       " 'Walter Pidgeon': 143,\n",
       " 'Greer Garson': 144,\n",
       " 'tay garnett': 145,\n",
       " 'The Wolf Man': 146,\n",
       " 'George Waggner': 147,\n",
       " 'Curt Siodmak': 148,\n",
       " 'Claude Rains': 149,\n",
       " 'Ralph Bellamy': 150,\n",
       " '1941': 151,\n",
       " 'werewolf': 152,\n",
       " 'A Cruel Romance': 153,\n",
       " 'Eldar Ryazanov': 154,\n",
       " '1984': 155,\n",
       " 'Russian': 156,\n",
       " 'Romance': 157,\n",
       " 'russian': 158,\n",
       " 'Love Happens': 159,\n",
       " 'Brandon Camp': 160,\n",
       " 'Aaron Eckhart': 161,\n",
       " 'Jennifer Aniston': 162,\n",
       " '2009': 163,\n",
       " 'jennifer aniston': 164,\n",
       " 'Innocence': 165,\n",
       " 'Hilary Brougher': 166,\n",
       " 'Tristine Skyler': 167,\n",
       " 'Jane Mendelsohn': 168,\n",
       " 'Kelly Reilly': 169,\n",
       " 'Linus Roache': 170,\n",
       " 'Graham Phillips': 171,\n",
       " 'Sophie Curtis': 172,\n",
       " 'Before the Rain': 173,\n",
       " 'Milcho Manchevski': 174,\n",
       " 'Katrin Cartlidge': 175,\n",
       " 'Grégoire Colin': 176,\n",
       " 'Labina Mitevska': 177,\n",
       " '1994': 178,\n",
       " 'Macedonian': 179,\n",
       " 'Radioland Murders': 180,\n",
       " 'Mel Smith': 181,\n",
       " 'George Lucas': 182,\n",
       " 'Willard Huyck': 183,\n",
       " 'Gloria Katz': 184,\n",
       " 'Ned Beatty': 185,\n",
       " 'Mary Stuart Masterson': 186,\n",
       " 'George Burns': 187,\n",
       " 'Brian Benben': 188,\n",
       " 'george lucas': 189,\n",
       " 'radio': 190,\n",
       " 'Sleep, My Love': 191,\n",
       " 'Douglas Sirk': 192,\n",
       " 'Robert Cummings': 193,\n",
       " 'Don Ameche': 194,\n",
       " 'Claudette Colbert': 195,\n",
       " '1948': 196,\n",
       " 'Cousins': 197,\n",
       " 'Joel Schumacher': 198,\n",
       " 'Sean Young': 199,\n",
       " 'Isabella Rossellini': 200,\n",
       " 'Ted Danson': 201,\n",
       " 'William Petersen': 202,\n",
       " '1989': 203,\n",
       " \"I Can't Sleep\": 204,\n",
       " 'Claire Denis': 205,\n",
       " 'Moonlight Mile': 206,\n",
       " 'Brad Silberling': 207,\n",
       " 'good': 208,\n",
       " \"China O'Brien\": 209,\n",
       " 'Cynthia Rothrock': 210,\n",
       " \"The Well-Digger's Daughter\": 211,\n",
       " 'Daniel Auteuil': 212,\n",
       " 'Marcel Pagnol': 213,\n",
       " 'Kad Merad': 214,\n",
       " 'Sabine Azéma': 215,\n",
       " '2011': 216,\n",
       " 'Chastity Bites': 217,\n",
       " 'John V. Knowles': 218,\n",
       " 'Lotti Pharriss Knowles': 219,\n",
       " '2013': 220,\n",
       " 'The Ice Storm': 221,\n",
       " 'Ang Lee': 222,\n",
       " 'Rick Moody': 223,\n",
       " 'Sigourney Weaver': 224,\n",
       " 'Kevin Kline': 225,\n",
       " 'Joan Allen': 226,\n",
       " '1997': 227,\n",
       " 'funny': 228,\n",
       " 'criterion': 229,\n",
       " 'drama': 230,\n",
       " 'dvd': 231,\n",
       " '1970s': 232,\n",
       " 'sigourney weaver': 233,\n",
       " 'moody': 234,\n",
       " 'elijah wood': 235,\n",
       " 'tobey maguire': 236,\n",
       " 'christina ricci': 237,\n",
       " 'ang lee': 238,\n",
       " 'thanksgiving': 239,\n",
       " 'Red Beard': 240,\n",
       " '1965': 241,\n",
       " 'Desperate Search': 242,\n",
       " 'Joseph H. Lewis': 243,\n",
       " 'Arthur Mayse': 244,\n",
       " 'Keenan Wynn': 245,\n",
       " 'Howard Keel': 246,\n",
       " 'Jane Greer': 247,\n",
       " 'Patricia Medina': 248,\n",
       " '1952': 249,\n",
       " 'Adventure': 250,\n",
       " 'The War Within': 251,\n",
       " 'Joseph Castelo': 252,\n",
       " 'Tom Glynn': 253,\n",
       " 'Ayad Akhtar': 254,\n",
       " 'Sarita Choudhury': 255,\n",
       " 'Nandana Sen': 256,\n",
       " 'Firdous Bamji': 257,\n",
       " 'Killer Movie': 258,\n",
       " 'Jeff Fisher': 259,\n",
       " 'Paul Wesley': 260,\n",
       " 'Torrey DeVitto': 261,\n",
       " '2008': 262,\n",
       " 'The Mighty Ducks': 263,\n",
       " 'Stephen Herek': 264,\n",
       " 'Emilio Estevez': 265,\n",
       " '1992': 266,\n",
       " 'sports': 267,\n",
       " 'emilio estevez': 268,\n",
       " 'stephen herek': 269,\n",
       " 'The Unknown Soldier': 270,\n",
       " 'Rauni Mollberg': 271,\n",
       " 'Väinö Linna': 272,\n",
       " '1985': 273,\n",
       " 'Finnish': 274,\n",
       " 'remake': 275,\n",
       " 'Martyrs': 276,\n",
       " 'Pascal Laugier': 277,\n",
       " 'horror': 278,\n",
       " 'french': 279,\n",
       " 'new french extremity': 280,\n",
       " 'Mighty Joe Young': 281,\n",
       " 'Ron Underwood': 282,\n",
       " 'Merian C. Cooper': 283,\n",
       " 'Ruth Rose': 284,\n",
       " 'Charlize Theron': 285,\n",
       " 'Bill Paxton': 286,\n",
       " '1998': 287,\n",
       " 'Family': 288,\n",
       " 'charlize theron': 289,\n",
       " 'bill paxton': 290,\n",
       " 'ron underwood': 291,\n",
       " 'Starlift': 292,\n",
       " 'Roy Del Ruth': 293,\n",
       " 'John D. Klorer': 294,\n",
       " 'Doris Day': 295,\n",
       " 'Virginia Mayo': 296,\n",
       " 'Gordon MacRae': 297,\n",
       " 'Gene Nelson': 298,\n",
       " '1951': 299,\n",
       " 'Musical': 300,\n",
       " 'The Raid 2': 301,\n",
       " 'Gareth Evans': 302,\n",
       " 'Iko Uwais': 303,\n",
       " 'Oka Antara': 304,\n",
       " 'Arifin Putra': 305,\n",
       " '2014': 306,\n",
       " 'Indonesian': 307,\n",
       " 'action': 308,\n",
       " 'martial arts': 309,\n",
       " 'indonesia': 310,\n",
       " 'gareth evans': 311,\n",
       " 'iko uwais': 312,\n",
       " 'Shriek If You Know What I Did Last Friday the Thirteenth': 313,\n",
       " 'John Blanchard': 314,\n",
       " 'The Bridges of Madison County': 315,\n",
       " 'Richard LaGravenese': 316,\n",
       " 'Robert James Waller': 317,\n",
       " 'Meryl Streep': 318,\n",
       " '1995': 319,\n",
       " 'meryl streep': 320,\n",
       " 'book': 321,\n",
       " 'affair': 322,\n",
       " 'iowa': 323,\n",
       " 'Net Worth': 324,\n",
       " 'Jerry Ciccoritti': 325,\n",
       " 'Don Truckey': 326,\n",
       " 'David Cruise': 327,\n",
       " 'Phil Savath': 328,\n",
       " 'Kevin Conway': 329,\n",
       " 'Aidan Devine': 330,\n",
       " 'Hanna': 331,\n",
       " 'Joe Wright': 332,\n",
       " 'Cate Blanchett': 333,\n",
       " 'Saoirse Ronan': 334,\n",
       " 'assassin': 335,\n",
       " 'cate blanchett': 336,\n",
       " 'saoirse ronan': 337,\n",
       " 'finland': 338,\n",
       " 'joe wright': 339,\n",
       " 'the chemical brothers': 340,\n",
       " 'De Dana Dan': 341,\n",
       " 'Priyadarshan': 342,\n",
       " 'Akshay Kumar': 343,\n",
       " 'Katrina Kaif': 344,\n",
       " 'Sunil Shetty': 345,\n",
       " 'Sameera Reddy': 346,\n",
       " 'Hindi': 347,\n",
       " 'Marnie': 348,\n",
       " 'Alfred Hitchcock': 349,\n",
       " 'Jay Presson Allen': 350,\n",
       " 'Winston Graham': 351,\n",
       " 'Sean Connery': 352,\n",
       " 'Tippi Hedren': 353,\n",
       " '1964': 354,\n",
       " 'psychological': 355,\n",
       " 'alfred hitchcock': 356,\n",
       " 'sean connery': 357,\n",
       " 'hitchcock': 358,\n",
       " 'psychological thriller': 359,\n",
       " 'bernard herrmann': 360,\n",
       " 'tippi hedren': 361,\n",
       " 'Dreams': 362,\n",
       " 'dreams': 363,\n",
       " 'life': 364,\n",
       " 'Toy Story 2': 365,\n",
       " 'Lee Unkrich': 366,\n",
       " 'John Lasseter': 367,\n",
       " 'Ash Brannon': 368,\n",
       " 'Joan Cusack': 369,\n",
       " '1999': 370,\n",
       " 'Animation': 371,\n",
       " 'animation': 372,\n",
       " 'pixar': 373,\n",
       " 'disney': 374,\n",
       " 'sequel': 375,\n",
       " 'original': 376,\n",
       " 'story': 377,\n",
       " 'characters': 378,\n",
       " 'light': 379,\n",
       " 'pixar animation': 380,\n",
       " 'joan cusack': 381,\n",
       " 'john lasseter': 382,\n",
       " 'lee unkrich': 383,\n",
       " 'The Marrying Kind': 384,\n",
       " 'George Cukor': 385,\n",
       " 'Garson Kanin': 386,\n",
       " 'Ruth Gordon': 387,\n",
       " 'Judy Holliday': 388,\n",
       " 'Aldo Ray': 389,\n",
       " 'Madge Kennedy': 390,\n",
       " 'george cukor': 391,\n",
       " 'My Favorite Season': 392,\n",
       " 'André Téchiné': 393,\n",
       " 'Catherine Deneuve': 394,\n",
       " 'Marthe Villalonga': 395,\n",
       " '1993': 396,\n",
       " 'andré téchiné': 397,\n",
       " 'Reflections in a Golden Eye': 398,\n",
       " 'John Huston': 399,\n",
       " 'Carson McCullers': 400,\n",
       " 'Marlon Brando': 401,\n",
       " 'Elizabeth Taylor': 402,\n",
       " '1967': 403,\n",
       " 'marlon brando': 404,\n",
       " 'john huston': 405,\n",
       " 'elizabeth taylor': 406,\n",
       " 'The Sensation of Sight': 407,\n",
       " 'David Strathairn': 408,\n",
       " 'Ian Somerhalder': 409,\n",
       " 'Jane Adams': 410,\n",
       " 'Daniel Gillies': 411,\n",
       " 'Call Me Bwana': 412,\n",
       " 'Gordon Douglas': 413,\n",
       " 'Anita Ekberg': 414,\n",
       " 'Bob Hope': 415,\n",
       " '1963': 416,\n",
       " 'Newlyweds': 417,\n",
       " 'Edward Burns': 418,\n",
       " 'Kerry Bishé': 419,\n",
       " 'Caitlin FitzGerald': 420,\n",
       " 'Marsha Dietlein': 421,\n",
       " 'Alps': 422,\n",
       " 'Yorgos Lanthimos': 423,\n",
       " 'Efthymis Filippou': 424,\n",
       " 'Ariane Labed': 425,\n",
       " 'Greek': 426,\n",
       " 'greek': 427,\n",
       " 'Halloween II': 428,\n",
       " 'Rob Zombie': 429,\n",
       " 'visual': 430,\n",
       " 'malcolm mcdowell': 431,\n",
       " 'Romeo Must Die': 432,\n",
       " 'Andrzej Bartkowiak': 433,\n",
       " 'Jet Li': 434,\n",
       " 'Isaiah Washington': 435,\n",
       " 'Aaliyah': 436,\n",
       " 'Russell Wong': 437,\n",
       " 'jet li': 438,\n",
       " 'andrzej bartkowiak': 439,\n",
       " '20,000 Leagues Under the Sea': 440,\n",
       " 'Jules Verne': 441,\n",
       " 'Ben Cross': 442,\n",
       " 'love triangle': 443,\n",
       " 'jules verne': 444,\n",
       " 'Miss Pettigrew Lives for a Day': 445,\n",
       " 'Bharat Nalluri': 446,\n",
       " 'Simon Beaufoy': 447,\n",
       " 'David Magee': 448,\n",
       " 'Winifred Watson': 449,\n",
       " 'The Business of Strangers': 450,\n",
       " 'Patrick Stettner': 451,\n",
       " 'Julia Stiles': 452,\n",
       " 'Stockard Channing': 453,\n",
       " '2001': 454,\n",
       " 'stockard channing': 455,\n",
       " 'The Saint': 456,\n",
       " 'Phillip Noyce': 457,\n",
       " 'Jonathan Hensleigh': 458,\n",
       " 'Wesley Strick': 459,\n",
       " 'Leslie Charteris': 460,\n",
       " 'Val Kilmer': 461,\n",
       " 'Elisabeth Shue': 462,\n",
       " 'espionage': 463,\n",
       " 'val kilmer': 464,\n",
       " 'international': 465,\n",
       " 'elisabeth shue': 466,\n",
       " 'phillip noyce': 467,\n",
       " 'The Grand Maneuver': 468,\n",
       " 'René Clair': 469,\n",
       " 'Michèle Morgan': 470,\n",
       " 'Gérard Philipe': 471,\n",
       " '1955': 472,\n",
       " 'rené clair': 473,\n",
       " 'David and Lisa': 474,\n",
       " 'Frank Perry': 475,\n",
       " 'Eleanor Perry': 476,\n",
       " 'Theodore Isaac Rubin': 477,\n",
       " '1962': 478,\n",
       " 'frank perry': 479,\n",
       " 'The Girl on the Train': 480,\n",
       " 'Larry Brand': 481,\n",
       " 'Stephen Lang': 482,\n",
       " 'Nicki Aycox': 483,\n",
       " 'Henry Ian Cusick': 484,\n",
       " 'Hoop Dreams': 485,\n",
       " 'Steve James': 486,\n",
       " 'Frederick Marx': 487,\n",
       " 'Documentary': 488,\n",
       " 'high school': 489,\n",
       " 'documentary': 490,\n",
       " 'school': 491,\n",
       " 'basketball': 492,\n",
       " 'chicago': 493,\n",
       " 'steve james': 494,\n",
       " 'Apartment 1303': 495,\n",
       " 'Ataru Oikawa': 496,\n",
       " \"Gilles' Wife\": 497,\n",
       " 'Frédéric Fonteyne': 498,\n",
       " 'Philippe Blasband': 499,\n",
       " 'Marion Hänsel': 500,\n",
       " 'Madeleine Bourdouxhe': 501,\n",
       " 'Thank You, Mr. Moto': 502,\n",
       " 'John P. Marquand': 503,\n",
       " 'Peter Lorre': 504,\n",
       " '1937': 505,\n",
       " 'Ninja Assassin': 506,\n",
       " 'James McTeigue': 507,\n",
       " 'J. Michael Straczynski': 508,\n",
       " 'Matthew Sand': 509,\n",
       " 'Rain': 510,\n",
       " 'violence': 511,\n",
       " 'dark': 512,\n",
       " 'ninja': 513,\n",
       " 'rain': 514,\n",
       " \"Hangman's Curse\": 515,\n",
       " 'Frank Peretti': 516,\n",
       " 'Leighton Meester': 517,\n",
       " 'Douglas Smith': 518,\n",
       " 'David Keith': 519,\n",
       " 'Mel Harris': 520,\n",
       " '2003': 521,\n",
       " 'Big Brown Eyes': 522,\n",
       " 'Cary Grant': 523,\n",
       " 'Joan Bennett': 524,\n",
       " '1936': 525,\n",
       " 'The Shipping News': 526,\n",
       " 'Lasse Hallström': 527,\n",
       " 'Annie Proulx': 528,\n",
       " 'Kevin Spacey': 529,\n",
       " 'Julianne Moore': 530,\n",
       " 'Judi Dench': 531,\n",
       " 'kevin spacey': 532,\n",
       " 'julianne moore': 533,\n",
       " 'judi dench': 534,\n",
       " 'Montana Sky': 535,\n",
       " 'Mike Robe': 536,\n",
       " 'Nora Roberts': 537,\n",
       " 'Ashley Williams': 538,\n",
       " 'Charlotte Ross': 539,\n",
       " '2007': 540,\n",
       " 'nora roberts': 541,\n",
       " 'Zorba the Greek': 542,\n",
       " 'Nikos Kazantzakis': 543,\n",
       " 'Anthony Quinn': 544,\n",
       " 'Irene Papas': 545,\n",
       " 'Alan Bates': 546,\n",
       " 'Lila Kedrova': 547,\n",
       " 'anthony quinn': 548,\n",
       " 'Sabah': 549,\n",
       " 'Ruba Nadda': 550,\n",
       " 'Arsinée Khanjian': 551,\n",
       " 'Captain Ron': 552,\n",
       " 'Thom Eberhardt': 553,\n",
       " 'John Dwyer': 554,\n",
       " 'Kurt Russell': 555,\n",
       " 'Martin Short': 556,\n",
       " 'Benjamin Salisbury': 557,\n",
       " 'Mary Kay Place': 558,\n",
       " 'comedy': 559,\n",
       " 'The Island': 560,\n",
       " 'Michael Bay': 561,\n",
       " 'Ewan McGregor': 562,\n",
       " 'Scarlett Johansson': 563,\n",
       " 'dystopia': 564,\n",
       " 'scarlett johansson': 565,\n",
       " 'ewan mcgregor': 566,\n",
       " 'michael bay': 567,\n",
       " 'Sometimes They Come Back... for More': 568,\n",
       " 'Daniel Zelik Berk': 569,\n",
       " 'Enough Said': 570,\n",
       " 'Nicole Holofcener': 571,\n",
       " 'james gandolfini': 572,\n",
       " 'nicole holofcener': 573,\n",
       " 'Secretary': 574,\n",
       " 'Steven Shainberg': 575,\n",
       " 'Mary Gaitskill': 576,\n",
       " 'Maggie Gyllenhaal': 577,\n",
       " 'James Spader': 578,\n",
       " 'romance': 579,\n",
       " 'sex': 580,\n",
       " 'erotic': 581,\n",
       " 'maggie gyllenhaal': 582,\n",
       " 'james spader': 583,\n",
       " 'secretary': 584,\n",
       " 'The Taste of Tea': 585,\n",
       " 'Katsuhito Ishii': 586,\n",
       " 'How They Get There': 587,\n",
       " 'Spike Jonze': 588,\n",
       " 'Short': 589,\n",
       " \"Merrill's Marauders\": 590,\n",
       " 'Samuel Fuller': 591,\n",
       " 'Charlton Ogburn Jr.': 592,\n",
       " 'Jeff Chandler': 593,\n",
       " 'Hyde Park on Hudson': 594,\n",
       " 'Roger Michell': 595,\n",
       " 'Bill Murray': 596,\n",
       " 'Laura Linney': 597,\n",
       " '2012': 598,\n",
       " 'bill murray': 599,\n",
       " 'laura linney': 600,\n",
       " 'Loving Leah': 601,\n",
       " 'Jeff Bleckner': 602,\n",
       " 'Pnenah Goldstein': 603,\n",
       " 'Lauren Ambrose': 604,\n",
       " 'Adam Kaufman': 605,\n",
       " 'jeff bleckner': 606,\n",
       " 'The Exorcist III': 607,\n",
       " 'William Peter Blatty': 608,\n",
       " 'George C. Scott': 609,\n",
       " 'Brad Dourif': 610,\n",
       " 'Ed Flanders': 611,\n",
       " 'Jason Miller': 612,\n",
       " 'Seven Ways from Sundown': 613,\n",
       " 'Clair Huffaker': 614,\n",
       " 'Audie Murphy': 615,\n",
       " 'Barry Sullivan': 616,\n",
       " '1960': 617,\n",
       " 'Western': 618,\n",
       " 'The Shawshank Redemption': 619,\n",
       " 'Frank Darabont': 620,\n",
       " 'Stephen King': 621,\n",
       " 'Morgan Freeman': 622,\n",
       " 'Tim Robbins': 623,\n",
       " 'morgan freeman': 624,\n",
       " 'acting': 625,\n",
       " 'stephen king': 626,\n",
       " 'vhs': 627,\n",
       " 'redemption': 628,\n",
       " 'tim robbins': 629,\n",
       " 'warm': 630,\n",
       " 'frank darabont': 631,\n",
       " 'rita hayworth': 632,\n",
       " \"You're Next\": 633,\n",
       " 'Adam Wingard': 634,\n",
       " 'Simon Barrett': 635,\n",
       " 'Sharni Vinson': 636,\n",
       " 'Wendy Glenn': 637,\n",
       " 'Nicholas Tucci': 638,\n",
       " 'slasher': 639,\n",
       " 'adam wingard': 640,\n",
       " \"I'll Cry Tomorrow\": 641,\n",
       " 'Daniel Mann': 642,\n",
       " 'Helen Deutsch': 643,\n",
       " 'Gerold Frank': 644,\n",
       " 'Mike Connolly': 645,\n",
       " 'Jay Richard Kennedy': 646,\n",
       " 'Lillian Roth': 647,\n",
       " 'Eddie Albert': 648,\n",
       " 'Jo Van Fleet': 649,\n",
       " 'Richard Conte': 650,\n",
       " 'Biography': 651,\n",
       " 'daniel mann': 652,\n",
       " 'Are You Listening?': 653,\n",
       " 'Harry Beaumont': 654,\n",
       " 'William Haines': 655,\n",
       " 'Anita Page': 656,\n",
       " 'Madge Evans': 657,\n",
       " 'harry beaumont': 658,\n",
       " 'Head': 659,\n",
       " 'Bob Rafelson': 660,\n",
       " 'Jack Nicholson': 661,\n",
       " 'bob rafelson': 662,\n",
       " 'Chicago Overcoat': 663,\n",
       " 'Brian Caunter': 664,\n",
       " 'Josh Staman': 665,\n",
       " 'Handle with Care': 666,\n",
       " 'Jonathan Demme': 667,\n",
       " '1977': 668,\n",
       " 'Golden Boy': 669,\n",
       " 'Clifford Odets': 670,\n",
       " 'Lee J. Cobb': 671,\n",
       " 'William Holden': 672,\n",
       " 'Barbara Stanwyck': 673,\n",
       " 'Adolphe Menjou': 674,\n",
       " '1939': 675,\n",
       " 'A Pure Formality': 676,\n",
       " 'Giuseppe Tornatore': 677,\n",
       " 'Gérard Depardieu': 678,\n",
       " 'Roman Polanski': 679,\n",
       " 'roman polanski': 680,\n",
       " 'gérard depardieu': 681,\n",
       " 'giuseppe tornatore': 682,\n",
       " \"The World's Greatest Athlete\": 683,\n",
       " 'John Amos': 684,\n",
       " 'Roscoe Lee Browne': 685,\n",
       " 'Tim Conway': 686,\n",
       " '1973': 687,\n",
       " 'The Killer': 688,\n",
       " 'John Woo': 689,\n",
       " 'Danny Lee': 690,\n",
       " 'Sally Yeh': 691,\n",
       " 'hong kong': 692,\n",
       " 'john woo': 693,\n",
       " 'chow yun fat': 694,\n",
       " 'The First Texan': 695,\n",
       " 'Byron Haskin': 696,\n",
       " 'Joel McCrea': 697,\n",
       " 'Felicia Farr': 698,\n",
       " '1956': 699,\n",
       " 'People of the Wind': 700,\n",
       " 'Anthony Howarth': 701,\n",
       " 'David Koff': 702,\n",
       " '1976': 703,\n",
       " 'The Boy Friend': 704,\n",
       " 'Ken Russell': 705,\n",
       " 'Sandy Wilson': 706,\n",
       " 'Max Adrian': 707,\n",
       " 'Twiggy': 708,\n",
       " 'Christopher Gable': 709,\n",
       " '1971': 710,\n",
       " 'ken russell': 711,\n",
       " 'Fido': 712,\n",
       " 'Andrew Currie': 713,\n",
       " 'Robert Chomiak': 714,\n",
       " 'Dennis Heaton': 715,\n",
       " 'canadian': 716,\n",
       " 'When the Wind Blows': 717,\n",
       " 'Raymond Briggs': 718,\n",
       " 'John Mills': 719,\n",
       " 'Peggy Ashcroft': 720,\n",
       " 'Blood Creek': 721,\n",
       " 'Michael Fassbender': 722,\n",
       " 'Henry Cavill': 723,\n",
       " 'Dominic Purcell': 724,\n",
       " 'Side by Side': 725,\n",
       " 'Christopher Kenneally': 726,\n",
       " 'keanu reeves': 727,\n",
       " 'film': 728,\n",
       " \"Midnight's Children\": 729,\n",
       " 'Deepa Mehta': 730,\n",
       " 'Salman Rushdie': 731,\n",
       " 'Anupam Kher': 732,\n",
       " 'Surf Ninjas': 733,\n",
       " 'Neal Israel': 734,\n",
       " 'Dan Gordon': 735,\n",
       " 'Ernie Reyes Jr.': 736,\n",
       " 'Nicolas Cowan': 737,\n",
       " 'neal israel': 738,\n",
       " 'The Art of the Steal': 739,\n",
       " 'Jonathan Sobol': 740,\n",
       " 'Jay Baruchel': 741,\n",
       " 'Matt Dillon': 742,\n",
       " 'jay baruchel': 743,\n",
       " '17 Again': 744,\n",
       " 'Burr Steers': 745,\n",
       " 'Leslie Mann': 746,\n",
       " 'Zac Efron': 747,\n",
       " 'Matthew Perry': 748,\n",
       " 'Thomas Lennon': 749,\n",
       " 'leslie mann': 750,\n",
       " 'matthew perry': 751,\n",
       " 'zac efron': 752,\n",
       " 'michelle trachtenberg': 753,\n",
       " 'More': 754,\n",
       " 'Barbet Schroeder': 755,\n",
       " 'Mimsy Farmer': 756,\n",
       " 'Klaus Grünberg': 757,\n",
       " '1969': 758,\n",
       " 'pink floyd': 759,\n",
       " 'Welcome Back, Mr. McDonald': 760,\n",
       " 'Keiko Toda': 761,\n",
       " 'Big Eden': 762,\n",
       " 'Thomas Bezucha': 763,\n",
       " 'gay': 764,\n",
       " 'The Three Stooges Meet Hercules': 765,\n",
       " 'Edward Bernds': 766,\n",
       " 'Moe Howard': 767,\n",
       " 'Larry Fine': 768,\n",
       " 'Joe DeRita': 769,\n",
       " 'Blindness': 770,\n",
       " 'Fernando Meirelles': 771,\n",
       " 'José Saramago': 772,\n",
       " 'Don McKellar': 773,\n",
       " 'blindness': 774,\n",
       " 'mark ruffalo': 775,\n",
       " 'epidemic': 776,\n",
       " 'fernando meirelles': 777,\n",
       " 'The Little Mermaid': 778,\n",
       " 'John Musker': 779,\n",
       " 'Ron Clements': 780,\n",
       " 'Hans Christian Andersen': 781,\n",
       " 'Howard Ashman': 782,\n",
       " 'Christopher Daniel Barnes': 783,\n",
       " 'Jodi Benson': 784,\n",
       " 'Pat Carroll': 785,\n",
       " 'Fantasy': 786,\n",
       " 'music': 787,\n",
       " 'own': 788,\n",
       " 'animated': 789,\n",
       " 'disney animated feature': 790,\n",
       " 'mermaid': 791,\n",
       " 'disney renaissance': 792,\n",
       " 'ron clements': 793,\n",
       " 'john musker': 794,\n",
       " 'Code Unknown': 795,\n",
       " 'Michael Haneke': 796,\n",
       " 'michael haneke': 797,\n",
       " 'haneke': 798,\n",
       " 'Two Lovers': 799,\n",
       " 'James Gray': 800,\n",
       " 'Joaquin Phoenix': 801,\n",
       " 'new york city': 802,\n",
       " 'gwyneth paltrow': 803,\n",
       " 'joaquin phoenix': 804,\n",
       " 'jewish': 805,\n",
       " 'james gray': 806,\n",
       " 'Vice': 807,\n",
       " 'Michael Madsen': 808,\n",
       " 'Remember Me': 809,\n",
       " 'Allen Coulter': 810,\n",
       " 'Will Fetters': 811,\n",
       " '2010': 812,\n",
       " 'pierce brosnan': 813,\n",
       " 'robert pattinson': 814,\n",
       " 'emilie de ravin': 815,\n",
       " 'Human Capital': 816,\n",
       " 'Paolo Virzì': 817,\n",
       " 'Stephen Amidon': 818,\n",
       " 'Valeria Bruni Tedeschi': 819,\n",
       " 'Italian': 820,\n",
       " 'Teeth': 821,\n",
       " 'Mitchell Lichtenstein': 822,\n",
       " 'The Day After': 823,\n",
       " 'Nicholas Meyer': 824,\n",
       " 'Edward Hume': 825,\n",
       " 'Jason Robards': 826,\n",
       " 'Steve Guttenberg': 827,\n",
       " 'JoBeth Williams': 828,\n",
       " 'John Cullum': 829,\n",
       " '1983': 830,\n",
       " 'nicholas meyer': 831,\n",
       " 'The Runner': 832,\n",
       " 'Amir Naderi': 833,\n",
       " 'Persian': 834,\n",
       " \"The Goalie's Anxiety at the Penalty Kick\": 835,\n",
       " 'Wim Wenders': 836,\n",
       " 'Peter Handke': 837,\n",
       " '1972': 838,\n",
       " 'The Rainmaker': 839,\n",
       " 'Francis Ford Coppola': 840,\n",
       " 'John Grisham': 841,\n",
       " 'Matt Damon': 842,\n",
       " 'Jon Voight': 843,\n",
       " 'Danny DeVito': 844,\n",
       " 'Claire Danes': 845,\n",
       " 'matt damon': 846,\n",
       " 'mickey rourke': 847,\n",
       " 'francis ford coppola': 848,\n",
       " 'danny devito': 849,\n",
       " 'claire danes': 850,\n",
       " 'john grisham': 851,\n",
       " 'danny glover': 852,\n",
       " 'jon voight': 853,\n",
       " 'virginia madsen': 854,\n",
       " 'teresa wright': 855,\n",
       " 'Uninvited Guest': 856,\n",
       " 'Timothy Wayne Folsome': 857,\n",
       " 'Mekhi Phifer': 858,\n",
       " 'Mari Morrow': 859,\n",
       " 'Mel Jackson': 860,\n",
       " 'Gunbuster': 861,\n",
       " 'Hideaki Anno': 862,\n",
       " '1988': 863,\n",
       " 'anime': 864,\n",
       " 'hideaki anno': 865,\n",
       " 'Black Swan': 866,\n",
       " 'Darren Aronofsky': 867,\n",
       " 'Natalie Portman': 868,\n",
       " 'Mila Kunis': 869,\n",
       " 'Vincent Cassel': 870,\n",
       " 'natalie portman': 871,\n",
       " 'dance': 872,\n",
       " 'mila kunis': 873,\n",
       " 'ballet': 874,\n",
       " 'darren aronofsky': 875,\n",
       " 'vincent cassel': 876,\n",
       " 'swan lake': 877,\n",
       " 'A Song to Remember': 878,\n",
       " 'Charles Vidor': 879,\n",
       " 'Paul Muni': 880,\n",
       " 'Cornel Wilde': 881,\n",
       " 'Merle Oberon': 882,\n",
       " 'Nina Foch': 883,\n",
       " '1945': 884,\n",
       " 'The Extra Man': 885,\n",
       " 'Robert Pulcini': 886,\n",
       " 'Shari Springer Berman': 887,\n",
       " 'Jonathan Ames': 888,\n",
       " 'Paul Dano': 889,\n",
       " 'Love Story': 890,\n",
       " 'Arthur Hiller': 891,\n",
       " 'Erich Segal': 892,\n",
       " \"Ryan O'Neal\": 893,\n",
       " 'Ray Milland': 894,\n",
       " 'Ali MacGraw': 895,\n",
       " 'John Marley': 896,\n",
       " '1970': 897,\n",
       " 'arthur hiller': 898,\n",
       " \"ryan o'neal\": 899,\n",
       " 'Generation Iron': 900,\n",
       " 'Arnold Schwarzenegger': 901,\n",
       " 'Mickey Rourke': 902,\n",
       " 'Lou Ferrigno': 903,\n",
       " 'Sport': 904,\n",
       " 'Ten North Frederick': 905,\n",
       " 'Philip Dunne': 906,\n",
       " \"John O'Hara\": 907,\n",
       " 'Gary Cooper': 908,\n",
       " 'Carry On... Up the Khyber': 909,\n",
       " 'Charles Hawtrey': 910,\n",
       " 'Kenneth Williams': 911,\n",
       " 'Roy Castle': 912,\n",
       " 'The Amityville Horror': 913,\n",
       " 'Stuart Rosenberg': 914,\n",
       " 'Jay Anson': 915,\n",
       " '1979': 916,\n",
       " 'stuart rosenberg': 917,\n",
       " 'Operation Crossbow': 918,\n",
       " 'Michael Anderson': 919,\n",
       " 'Emeric Pressburger': 920,\n",
       " 'Vittoriano Petrilli': 921,\n",
       " 'Ray Rigby': 922,\n",
       " 'Duilio Coletti': 923,\n",
       " 'Derry Quinn': 924,\n",
       " 'German': 925,\n",
       " 'Operation Mad Ball': 926,\n",
       " 'Richard Quine': 927,\n",
       " 'Blake Edwards': 928,\n",
       " 'Jed Harris': 929,\n",
       " 'Arthur Carter': 930,\n",
       " 'Jack Lemmon': 931,\n",
       " \"Arthur O'Connell\": 932,\n",
       " 'Ernie Kovacs': 933,\n",
       " 'Kathryn Grant': 934,\n",
       " '1957': 935,\n",
       " 'Filth and Wisdom': 936,\n",
       " 'Madonna': 937,\n",
       " 'Richard E. Grant': 938,\n",
       " 'Vicky McClure': 939,\n",
       " 'Holly Weston': 940,\n",
       " 'madonna': 941,\n",
       " 'Straight Shooting': 942,\n",
       " 'John Ford': 943,\n",
       " 'Harry Carey': 944,\n",
       " '1917': 945,\n",
       " 'Girl 27': 946,\n",
       " 'David Stenn': 947,\n",
       " 'Wind Across the Everglades': 948,\n",
       " 'Nicholas Ray': 949,\n",
       " 'Budd Schulberg': 950,\n",
       " 'Christopher Plummer': 951,\n",
       " 'Gypsy Rose Lee': 952,\n",
       " 'Unfair Competition': 953,\n",
       " 'Ettore Scola': 954,\n",
       " 'ettore scola': 955,\n",
       " 'Good Morning, Night': 956,\n",
       " 'Marco Bellocchio': 957,\n",
       " 'Great Day in the Morning': 958,\n",
       " 'Jacques Tourneur': 959,\n",
       " 'Robert Stack': 960,\n",
       " \"Ain't Them Bodies Saints\": 961,\n",
       " 'David Lowery': 962,\n",
       " 'Rooney Mara': 963,\n",
       " 'Casey Affleck': 964,\n",
       " 'Small Soldiers': 965,\n",
       " 'Joe Dante': 966,\n",
       " 'kirsten dunst': 967,\n",
       " 'joe dante': 968,\n",
       " 'Where the Money Is': 969,\n",
       " 'Marek Kanievska': 970,\n",
       " 'E. Max Frye': 971,\n",
       " 'Paul Newman': 972,\n",
       " 'Dermot Mulroney': 973,\n",
       " 'Linda Fiorentino': 974,\n",
       " 'Seven Swords': 975,\n",
       " 'Donnie Yen': 976,\n",
       " 'Charlie Yeung': 977,\n",
       " 'Leon Lai': 978,\n",
       " 'Dante 01': 979,\n",
       " 'Marc Caro': 980,\n",
       " 'Oedipus Rex': 981,\n",
       " 'Pier Paolo Pasolini': 982,\n",
       " 'pier paolo pasolini': 983,\n",
       " 'Steven Spielberg': 984,\n",
       " 'Robert Zemeckis': 985,\n",
       " 'Bob Gale': 986,\n",
       " 'Dan Aykroyd': 987,\n",
       " 'John Belushi': 988,\n",
       " 'Born to Be Bad': 989,\n",
       " 'Lowell Sherman': 990,\n",
       " 'Loretta Young': 991,\n",
       " '1934': 992,\n",
       " 'Towelhead': 993,\n",
       " 'Alan Ball': 994,\n",
       " 'Alicia Erian': 995,\n",
       " 'The 19th Wife': 996,\n",
       " 'David Ebershoff': 997,\n",
       " 'Chyler Leigh': 998,\n",
       " 'Matt Czuchry': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb_mgr.entity_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EmbedKGQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what sort of film is Alpha Dog\n",
      "Alpha Dog\n",
      "['Drama', 'Crime']\n",
      "\n",
      "96106 9992 9947\n"
     ]
    }
   ],
   "source": [
    "class QA:\n",
    "    def __init__(self, question, answers, question_entity):\n",
    "        self.question = question\n",
    "        self.answers = answers\n",
    "        self.question_entity = question_entity\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"{}\\n{}\\n{}\\n\".format(self.question, self.question_entity, self.answers)\n",
    "        \n",
    "def read_dataset(path):\n",
    "    dataset = []\n",
    "    with open(path, 'r') as f:\n",
    "        data_lines = f.read().strip().split('\\n')\n",
    "        for line in data_lines:\n",
    "            question_raw, ans_raw = line.split('\\t')\n",
    "            q_entity = re.search(r'\\[.+\\]', question_raw).group().strip('[]')\n",
    "            question = question_raw.replace(']', '').replace('[', '')\n",
    "            answers = ans_raw.strip().split('|')\n",
    "            dataset.append(QA(\n",
    "                question=question,\n",
    "                answers=answers,\n",
    "                question_entity=q_entity\n",
    "            ))\n",
    "    random.shuffle(dataset)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = read_dataset('./data/1-hop/qa_train.txt')\n",
    "valid_dataset = read_dataset('./data/1-hop/qa_dev.txt')\n",
    "test_dataset = read_dataset('./data/1-hop/qa_test.txt')\n",
    "\n",
    "print(test_dataset[1])\n",
    "print(len(train_dataset), len(valid_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0817 21:02:36.340466 140365751764800 tokenization_utils_base.py:1254] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/navid/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0817 21:02:36.342034 140365751764800 tokenization_utils_base.py:1254] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/navid/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0817 21:02:37.813474 140365751764800 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /home/navid/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
      "I0817 21:02:37.816820 140365751764800 configuration_utils.py:300] Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0817 21:02:40.197761 140365751764800 modeling_tf_utils.py:473] loading weights file https://cdn.huggingface.co/roberta-base-tf_model.h5 from cache at /home/navid/.cache/torch/transformers/2e18f106492efe1a8e6766e4d4e0bf4a82cee267c0cc52af431cf97005d4e3db.34733ed140f011f207fb07b32b443050356e99a9638db284a22d77bd3d5f54b3.h5\n",
      "W0817 21:02:43.106965 140365751764800 modeling_tf_utils.py:511] Some weights of the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "W0817 21:02:43.107517 140365751764800 modeling_tf_utils.py:528] All the weights of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "q_embedder = TFRobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "inputs = tokenizer(\n",
    "    [\"Hello, my dog is cute and nice\", \"hey man!\"],\n",
    "    return_tensors=\"tf\",\n",
    "    padding=True\n",
    ")\n",
    "outputs = q_embedder(inputs)\n",
    "last_hidden_states = outputs[0]\n",
    "\n",
    "last_hidden_states.numpy()[:, 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[-5.68278097e-02,  7.45838210e-02, -1.55453430e-02,\n",
       "          -1.18482023e-01,  5.48469238e-02, -1.20152578e-01,\n",
       "          -1.99890602e-02,  1.69902574e-02,  3.33256572e-02,\n",
       "          -5.86458184e-02, -7.99875893e-03,  3.83028537e-02,\n",
       "           3.51682790e-02, -3.10699511e-02,  9.35465693e-02,\n",
       "           3.14213783e-02, -8.18562806e-02,  2.19148360e-02,\n",
       "           3.11452597e-02, -4.50817607e-02, -9.96649936e-02,\n",
       "           3.61345410e-02, -5.69843017e-02,  1.17892370e-01,\n",
       "           7.67162256e-03,  3.29993814e-02,  7.09764063e-02,\n",
       "           9.56672356e-02, -3.93315926e-02, -1.65858027e-03,\n",
       "          -6.66877814e-03, -1.92997921e-02,  2.99060810e-02,\n",
       "          -5.10813892e-02,  4.07264791e-02,  5.32149039e-02,\n",
       "           6.59779608e-02,  3.00106639e-03, -1.24427065e-01,\n",
       "           6.19131327e-03, -2.71666963e-02,  3.82598937e-02,\n",
       "           1.68873724e-02,  3.36392894e-02,  6.67385608e-02,\n",
       "           5.12889214e-02,  1.33828791e-02,  2.48748660e-02,\n",
       "          -4.09413986e-02,  1.91048160e-02,  3.59678343e-02,\n",
       "           6.96614683e-02, -4.08727303e-02, -2.79393233e-03,\n",
       "          -7.11601228e-02,  2.73454525e-02, -6.50789216e-03,\n",
       "           7.67745301e-02,  4.63571958e-02, -1.85146984e-02,\n",
       "           1.13434093e-02, -9.90361869e-02, -9.59881544e-02,\n",
       "          -1.85380839e-02,  3.99070941e-02, -2.55820807e-02,\n",
       "          -4.03279886e-02, -9.25258175e-03,  3.32190581e-02,\n",
       "           4.09161001e-02,  6.64284453e-02, -1.21003874e-02,\n",
       "           6.45703673e-02, -2.58835163e-02, -3.51027548e-02,\n",
       "           3.95746157e-02,  2.87985988e-03,  5.31202674e-01,\n",
       "          -2.15873159e-02, -1.29622938e-02,  5.91626205e-02,\n",
       "          -1.28004849e-02,  3.55600327e-01,  4.58660163e-02,\n",
       "           2.09672842e-02,  1.00917164e-02,  5.95140234e-02,\n",
       "           5.02990223e-02, -5.58434613e-03,  3.82455252e-02,\n",
       "           1.59389302e-02,  5.05698696e-02, -7.16327578e-02,\n",
       "           1.93763040e-02,  6.99722208e-03,  7.01119453e-02,\n",
       "          -4.47787519e-04, -2.73037925e-02, -2.86844820e-02,\n",
       "          -5.74082546e-02, -2.03766301e-03, -6.64553419e-02,\n",
       "           1.03400923e-01,  5.39942235e-02, -1.34350844e-02,\n",
       "           2.26499960e-02,  3.66052315e-02, -1.88186802e-02,\n",
       "           1.51413381e-02, -2.54483242e-02,  1.27026476e-02,\n",
       "           5.28402403e-02, -2.79120542e-03,  7.32434243e-02,\n",
       "          -1.58204064e-02, -3.58641446e-02,  2.25995481e-03,\n",
       "           1.02005498e-02, -1.63753852e-02,  3.85621600e-02,\n",
       "           3.06201540e-02,  1.00013718e-01,  1.06315166e-01,\n",
       "          -3.66714783e-02, -3.66088636e-02, -1.13669354e-02,\n",
       "          -9.81766917e-03, -1.02930963e-02, -2.87966635e-02,\n",
       "           5.76236621e-02,  2.18575038e-02, -4.97673303e-02,\n",
       "          -8.25474225e-03,  9.48474407e-02,  5.76283410e-02,\n",
       "           2.33697668e-02,  6.61838651e-02, -1.20052546e-02,\n",
       "           5.07275760e-02, -1.34437904e-03, -4.37151268e-02,\n",
       "           6.87943250e-02,  6.34331703e-02,  5.46609536e-02,\n",
       "           9.96754840e-02, -1.64250471e-03,  3.97142060e-02,\n",
       "          -1.66076291e-02,  2.99851820e-02, -2.11715586e-02,\n",
       "           7.62172416e-02, -4.80700508e-02, -4.50890400e-02,\n",
       "           1.04442462e-02,  3.32142860e-02,  3.94279927e-01,\n",
       "           6.53350800e-02,  2.30483860e-02, -2.95773931e-02,\n",
       "           1.46647040e-02,  1.60250187e-01,  5.43659553e-04,\n",
       "          -2.84160953e-03, -2.86427513e-03, -1.52502730e-02,\n",
       "           5.44838980e-03, -1.64168850e-02,  4.54720482e-02,\n",
       "           2.78619565e-02,  8.15517083e-03,  6.54863566e-02,\n",
       "           3.71057466e-02,  1.54707916e-02, -1.72924437e-02,\n",
       "          -5.09579964e-02, -8.25569779e-02, -1.21599194e-02,\n",
       "          -1.84039660e-02, -1.19603172e-01, -4.62147174e-04,\n",
       "           5.85893244e-02,  5.99181913e-02, -9.08999965e-02,\n",
       "           7.28551671e-03, -3.89488712e-02,  1.62860714e-02,\n",
       "           2.25173682e-03,  1.98302902e-02,  1.62944496e-02,\n",
       "          -1.84655488e-02,  5.11206686e-02, -4.55486812e-02,\n",
       "           2.08813883e-03,  1.27678085e-02, -3.91343702e-03,\n",
       "           1.00646578e-01, -2.68644672e-02, -1.04032420e-02,\n",
       "           2.60515027e-02, -3.14827301e-02,  4.50004339e-02,\n",
       "          -7.72751719e-02,  5.70219532e-02, -7.33072162e-02,\n",
       "           6.33625463e-02, -2.41525508e-02,  5.18668443e-04,\n",
       "           6.46536127e-02,  4.63119224e-02, -5.08434027e-02,\n",
       "          -5.97545840e-02,  3.84770446e-02,  2.38685198e-02,\n",
       "           7.00172335e-02,  8.55431706e-03, -5.73557615e-03,\n",
       "           5.20079210e-02,  1.04552716e-01, -1.56230200e-02,\n",
       "          -3.71501409e-02,  3.37285362e-02,  6.03528544e-02,\n",
       "          -2.98275612e-03,  7.26597607e-02, -1.49792135e-02,\n",
       "          -1.03753712e-02, -1.46332569e-02, -1.65217984e-02,\n",
       "           1.23561546e-02, -1.94982626e-02, -1.29343420e-02,\n",
       "           3.40487361e-02,  2.26740502e-02, -3.56506966e-02,\n",
       "           4.51212153e-02, -1.23720981e-01, -1.83279868e-02,\n",
       "          -6.24684319e-02, -1.79598145e-02,  4.39519919e-02,\n",
       "          -1.34626895e-01,  2.62411274e-02,  5.57938963e-02,\n",
       "           8.30584206e-03,  3.27820778e-02,  2.35755909e-02,\n",
       "           2.39394270e-02,  9.07980874e-02, -2.63627097e-02,\n",
       "           8.33034366e-02, -4.10605222e-03,  3.15801203e-02,\n",
       "          -2.80735083e-02, -1.21777309e-02,  4.07297239e-02,\n",
       "          -4.61657569e-02, -8.97999406e-02, -3.01722437e-04,\n",
       "           3.86033505e-02,  5.34981862e-03, -2.12883521e-02,\n",
       "          -7.23308846e-02,  3.77288125e-02, -4.35665362e-02,\n",
       "          -1.26693130e-01, -5.80699667e-02,  2.25802884e-04,\n",
       "           5.23461923e-02, -1.09792985e-02, -7.09077120e-02,\n",
       "           1.12294462e-02, -2.63447408e-02, -4.11819741e-02,\n",
       "           4.56325039e-02,  3.68606374e-02,  5.73366322e-02,\n",
       "          -4.21235077e-02, -3.80290858e-02, -8.23947340e-02,\n",
       "          -2.13840529e-02,  4.17230651e-02, -4.23893332e-04,\n",
       "          -7.59065971e-02,  2.52291299e-02, -2.42848378e-02,\n",
       "           3.36189941e-02, -1.15431845e-03, -3.28920893e-02,\n",
       "           2.05249023e-02,  4.05922905e-02,  3.44976448e-02,\n",
       "           1.09381564e-02, -4.26272303e-03,  3.44888009e-02,\n",
       "          -5.90854846e-02,  6.82781786e-02,  7.45782852e-02,\n",
       "          -6.72251638e-03,  2.05586515e-02, -1.03972480e-03,\n",
       "          -4.61691618e-02, -1.02608919e-01, -1.00340314e-01,\n",
       "          -1.96808875e-02,  5.07882424e-03, -7.18203932e-02,\n",
       "          -8.72291625e-03, -2.36828700e-02,  5.39491773e-02,\n",
       "          -6.59629051e-03, -4.61725406e-02, -3.50114703e-02,\n",
       "          -1.40141129e-01,  1.17205501e-01,  3.53353061e-02,\n",
       "          -4.02042009e-02,  5.60309179e-02, -5.24930395e-02,\n",
       "           2.53071561e-02,  1.79146212e-02,  4.49626148e-03,\n",
       "           1.38004217e-02,  7.32689351e-02,  2.09741145e-02,\n",
       "          -3.05834003e-02,  2.11202502e-02,  4.59332466e-02,\n",
       "          -1.56834088e-02,  4.63468991e-02,  4.02371973e-01,\n",
       "          -2.67237365e-01,  1.54222697e-02,  4.01388295e-02,\n",
       "           5.50123863e-02,  7.97414780e-02, -2.69851089e-03,\n",
       "           5.17080165e-02,  3.36935855e-02,  4.84349281e-02,\n",
       "           4.99845371e-02, -1.74065772e-02,  4.40594852e-02,\n",
       "           6.25231117e-03,  1.25948964e-02,  5.22374026e-02,\n",
       "           1.91827044e-02, -4.68433611e-02,  2.10630447e-02,\n",
       "          -6.11216947e-03, -1.91617757e-03,  1.49956988e-02,\n",
       "          -3.45245451e-02,  1.05727948e-02, -3.08930464e-02,\n",
       "          -2.74547301e-02,  1.53247975e-02,  2.84465216e-02,\n",
       "          -1.34116188e-02, -5.21477759e-02, -1.26874968e-02,\n",
       "           5.81379682e-02,  6.12092204e-03,  3.97418663e-02,\n",
       "          -1.70742143e-02,  9.25138444e-02, -9.28478390e-02,\n",
       "           4.32930887e-04,  6.49801493e-02,  1.05771497e-02,\n",
       "           1.51486900e-02,  8.43645409e-02, -3.00200284e-02,\n",
       "          -1.24543374e-02,  3.55392024e-02,  5.08273430e-02,\n",
       "           3.69402394e-03,  3.55262496e-02,  1.08240275e-02,\n",
       "          -2.65529333e-03,  8.32851753e-02,  3.43934074e-02,\n",
       "           1.72253735e-02, -4.55739200e-02,  2.62634456e-02,\n",
       "           5.21546900e-02, -5.54690883e-03,  2.48521604e-02,\n",
       "           1.27285719e-02,  9.47304741e-02, -1.01121105e-02,\n",
       "          -2.93033011e-02, -9.98231992e-02, -7.47570489e-03,\n",
       "          -6.48960993e-02,  9.06111747e-02, -1.21112308e-02,\n",
       "          -3.62966321e-02, -1.55777544e-01, -2.52085030e-02,\n",
       "          -8.98550898e-02,  4.57346402e-02,  7.85053074e-02,\n",
       "          -3.28849927e-02, -9.43761785e-03,  1.31337708e-02,\n",
       "           1.16861872e-02,  7.97372311e-04, -5.33542112e-02,\n",
       "           7.03290477e-03, -2.34055556e-02, -1.91346891e-02,\n",
       "           5.42305782e-02,  2.87822057e-02, -3.12399007e-02,\n",
       "           1.05176233e-02, -2.95446925e-02,  3.58828530e-02,\n",
       "           2.64034495e-02, -2.45238785e-02,  8.02341383e-03,\n",
       "          -4.23076376e-02,  5.07190786e-02,  2.57121846e-02,\n",
       "           1.05352281e-02, -7.13617280e-02, -1.97288841e-02,\n",
       "           2.68094577e-02, -5.50160073e-02, -2.73588598e-02,\n",
       "          -1.78530626e-03, -1.46038737e-02,  6.81403279e-02,\n",
       "          -6.80945367e-02, -1.19983274e-02, -1.58193931e-02,\n",
       "          -2.90001743e-02,  4.47879359e-03, -1.84821747e-02,\n",
       "          -5.21255210e-02, -4.21533585e-02, -5.15143983e-02,\n",
       "          -1.67201236e-02,  3.73946242e-02,  1.28154047e-02,\n",
       "          -9.60186422e-02,  4.68054041e-03,  7.23473579e-02,\n",
       "           1.32038835e-02, -1.16553344e-01,  1.72905605e-02,\n",
       "           4.43732291e-02,  6.20243251e-02, -3.96698266e-02,\n",
       "          -6.75852716e-01,  9.76323634e-02,  2.16730181e-02,\n",
       "           2.05058753e-02,  2.80673876e-02, -6.27087355e-02,\n",
       "           4.01286595e-03,  1.93377566e-02,  4.96660769e-02,\n",
       "           4.87698875e-02, -5.54000437e-02,  1.90147944e-02,\n",
       "           1.80203933e-02, -4.52443771e-02,  2.95038782e-02,\n",
       "          -2.94979867e-02, -2.95822211e-02,  5.03926389e-02,\n",
       "          -1.77686103e-02, -2.35258229e-03, -3.41072716e-02,\n",
       "           6.12948090e-03, -3.48535478e-02, -2.69088093e-02,\n",
       "           7.27532208e-02, -1.90754216e-02, -8.24096054e-02,\n",
       "          -3.73568498e-02,  4.90786806e-02,  4.31843325e-02,\n",
       "          -1.85230542e-02, -6.08211458e-02, -1.25938859e-02,\n",
       "           1.33937635e-02,  3.84284519e-02,  7.51560479e-02,\n",
       "           1.00067891e-02, -1.19298361e-02, -4.45926674e-02,\n",
       "           1.54006779e-02,  1.46698542e-02,  2.22632229e-01,\n",
       "           5.51904179e-03,  2.20422685e-01,  1.27937365e-02,\n",
       "           1.72052309e-02, -2.74833217e-02, -1.43132564e-02,\n",
       "          -2.10103579e-02,  1.16773956e-02,  1.73794851e-02,\n",
       "           2.25476315e-03, -1.83318406e-02, -7.92652965e-02,\n",
       "          -4.45672721e-02, -8.78965948e-03,  2.25945450e-02,\n",
       "          -2.68710479e-02, -5.60353138e-03,  1.29732892e-01,\n",
       "          -3.32034454e-02,  3.86509672e-02,  2.11941432e-02,\n",
       "           4.41619419e-02, -2.51026675e-02, -3.45453508e-02,\n",
       "          -3.31198610e-03, -5.46157099e-02,  2.35694759e-02,\n",
       "          -4.15741056e-02, -6.10078648e-02, -5.28106019e-02,\n",
       "          -3.37789543e-02,  3.52788493e-02,  1.66164171e-02,\n",
       "           6.47186637e-02,  1.05387382e-02, -6.92293141e-03,\n",
       "          -2.95317546e-03,  6.26990199e-02, -6.40614610e-03,\n",
       "           5.21893054e-02,  5.81861660e-02,  8.69821906e-02,\n",
       "           2.63506398e-02, -8.33957344e-02, -4.58281189e-02,\n",
       "          -1.39376707e-03,  2.75967102e-02,  1.30617023e-01,\n",
       "          -3.33095267e-02,  8.65551084e-02,  4.10487615e-02,\n",
       "          -4.94642276e-03, -2.81506199e-02,  3.79596204e-02,\n",
       "           4.23540175e-02,  9.15581547e-03, -6.85383439e-01,\n",
       "          -7.66921788e-02,  3.48496996e-02,  3.71809676e-02,\n",
       "           3.24916020e-02,  4.72789332e-02,  9.82965156e-03,\n",
       "          -3.73317972e-02,  7.27442056e-02, -3.03240884e-02,\n",
       "          -1.13307061e-02, -2.24476308e-02,  6.64567575e-02,\n",
       "          -6.19801283e-02,  2.22391337e-02,  5.75121269e-02,\n",
       "          -3.08410190e-02, -5.83786778e-02, -2.82424036e-03,\n",
       "          -2.94477433e-01, -1.23204719e-02, -5.20458631e-02,\n",
       "           9.99793708e-02,  5.67097310e-03,  1.96306724e-02,\n",
       "           6.82199001e-02, -3.94369252e-02,  2.70770416e-02,\n",
       "           9.68568474e-02,  2.87703350e-02,  6.84010759e-02,\n",
       "           4.34770882e-02, -2.88848151e-02,  4.47996669e-02,\n",
       "           2.46952176e-02,  6.39710650e-02, -1.36829261e-03,\n",
       "           1.08332748e+01, -7.03631341e-03,  6.32731616e-02,\n",
       "           2.35221200e-02, -1.41246151e-02, -6.75920844e-02,\n",
       "           9.02967751e-02, -2.60867216e-02,  1.10184439e-02,\n",
       "           9.92355794e-02,  1.15188304e-03,  1.99605674e-02,\n",
       "          -1.15939401e-01,  1.58937294e-02,  3.31597850e-02,\n",
       "           3.10687050e-02, -6.41859621e-02, -4.98440452e-02,\n",
       "           5.52248396e-02, -3.50855738e-02, -5.93999401e-03,\n",
       "           9.14210081e-03,  1.66913942e-02,  3.95396128e-02,\n",
       "          -6.44345209e-02, -1.88046955e-02,  2.89742835e-03,\n",
       "          -7.82022066e-03, -4.40533906e-02, -1.31674204e-02,\n",
       "           3.27092782e-02,  2.25848649e-02,  3.17086838e-02,\n",
       "           2.31857207e-02,  2.87185423e-02, -1.72188040e-02,\n",
       "          -2.24092081e-02,  8.73777792e-02,  1.11713316e-02,\n",
       "           7.63623863e-02,  6.16840757e-02, -1.30366506e-02,\n",
       "          -8.42596591e-03, -2.08397433e-02,  6.27537295e-02,\n",
       "           4.63337302e-02, -6.49503171e-02,  7.84385204e-02,\n",
       "           3.12213823e-02,  7.78853148e-02,  5.04823439e-02,\n",
       "          -5.86910918e-02,  4.60200384e-02,  4.71723676e-02,\n",
       "          -8.35595280e-03, -3.31614166e-03,  8.75641406e-02,\n",
       "          -1.32400142e-02,  6.26251400e-02,  4.66904081e-02,\n",
       "          -3.64347473e-02,  7.63784721e-02,  1.46645941e-02,\n",
       "           1.97152644e-02, -6.68988079e-02,  9.44625288e-02,\n",
       "           7.29778707e-02,  9.10110548e-02, -2.42152456e-02,\n",
       "           3.30386870e-02,  3.13674891e-03, -4.59964946e-02,\n",
       "          -2.59077288e-02, -1.94221251e-02, -2.37135589e-03,\n",
       "          -7.21278340e-02,  1.72875263e-02, -1.32888239e-02,\n",
       "           1.58206206e-02, -6.05171919e-03,  6.32821545e-02,\n",
       "          -1.58536751e-02, -1.93231329e-02, -1.76794454e-02,\n",
       "           9.57054719e-02,  1.80560816e-02,  1.00641642e-02,\n",
       "           7.99116045e-02,  4.58940398e-04,  6.07705861e-03,\n",
       "          -5.36422096e-02,  8.35870020e-03,  1.79034937e-02,\n",
       "          -6.18091822e-02,  2.47270949e-02,  1.15193799e-02,\n",
       "          -2.37138271e-02, -6.57421872e-02,  5.87088428e-02,\n",
       "           5.44626042e-02, -6.31015599e-02,  3.76714766e-02,\n",
       "          -1.50424931e-02,  8.08199793e-02, -7.17599504e-03,\n",
       "           1.79409552e-02, -2.37184465e-02, -2.95706354e-02,\n",
       "           4.37968411e-03, -1.24638453e-02, -1.39293447e-02,\n",
       "           2.67626308e-02, -2.18219236e-02, -2.36969404e-02,\n",
       "           3.73552106e-02,  3.04560363e-02,  9.10059549e-03,\n",
       "           6.07960671e-02,  9.90227889e-03,  4.80423085e-02,\n",
       "          -6.92316294e-02,  4.35739197e-03, -1.79246515e-02,\n",
       "          -1.62388235e-02, -1.22846290e-02, -5.14529347e-02,\n",
       "          -3.58213633e-02, -1.58346947e-02,  1.12013519e-03,\n",
       "          -4.32504620e-03, -4.61841375e-02,  2.66140047e-02,\n",
       "           6.09432086e-02, -5.00902068e-03,  5.44616161e-03,\n",
       "          -2.95501854e-03, -2.21715011e-02,  1.01071879e-01,\n",
       "           6.69325888e-02,  5.61921671e-02, -3.71621847e-02,\n",
       "          -7.72996992e-03, -1.91263929e-02, -8.51953104e-02,\n",
       "          -1.11293122e-02,  4.86207660e-03,  7.60150775e-02,\n",
       "           2.62524523e-02,  7.03619942e-02,  6.23736018e-03,\n",
       "           6.86981678e-02,  4.64727618e-02,  2.95548812e-02,\n",
       "          -2.30500940e-02,  3.03260610e-02, -3.57418954e-02,\n",
       "          -2.15490162e-03,  4.55221087e-02,  9.75868758e-03,\n",
       "          -1.38482600e-02,  4.79677059e-02, -3.88340466e-02,\n",
       "          -2.80925874e-02, -9.11927968e-03, -2.00658366e-02,\n",
       "          -4.40834761e-02, -6.25150055e-02,  1.69592798e-02,\n",
       "          -4.59068455e-03,  7.45051913e-03,  3.11208926e-02,\n",
       "          -1.61989965e-03, -4.76268046e-02, -7.41405264e-02,\n",
       "          -4.23421338e-03,  1.22217730e-01,  7.48993307e-02,\n",
       "          -7.13969618e-02, -6.49294257e-02, -7.21581234e-03]], dtype=float32),\n",
       "  array([[-5.55596873e-02, -9.37963650e-03,  2.89567970e-02,\n",
       "           8.98277089e-02, -1.19288646e-01, -1.54700009e-02,\n",
       "           3.09960060e-02,  4.24364246e-02,  4.44005616e-02,\n",
       "           3.94806638e-03,  1.13616444e-01,  8.52974653e-02,\n",
       "          -1.05942236e-02,  7.70778880e-02,  6.71834797e-02,\n",
       "          -1.26297787e-01,  9.85209495e-02,  5.56860529e-02,\n",
       "           3.61861214e-02,  9.38557237e-02, -4.27038819e-02,\n",
       "           1.00418171e-02,  1.93387672e-01,  4.26242575e-02,\n",
       "          -1.04456790e-01,  8.67933966e-03, -5.08431438e-03,\n",
       "           9.02040303e-02,  8.30455199e-02,  9.37367789e-03,\n",
       "           3.52703631e-02,  1.91821065e-02, -6.79272180e-03,\n",
       "           8.91303793e-02,  1.66749507e-02, -4.67722751e-02,\n",
       "           6.29449710e-02,  6.08067103e-02, -2.07691491e-02,\n",
       "           1.77614048e-01,  4.42014113e-02, -5.85468039e-02,\n",
       "          -4.23843339e-02,  7.71180391e-02,  5.47450967e-02,\n",
       "          -1.67275476e-03,  3.74689512e-02, -1.66773140e-01,\n",
       "           9.95427445e-02,  7.56838024e-02, -3.82110514e-02,\n",
       "           9.99873132e-03, -1.33309051e-01,  1.44625351e-01,\n",
       "          -1.23215206e-01, -6.15161508e-02, -7.53175840e-02,\n",
       "           1.42936567e-02, -8.81334953e-03,  4.70709838e-02,\n",
       "           4.29505110e-03, -1.08338911e-02, -1.94848143e-02,\n",
       "          -6.99882209e-02,  2.15489091e-03,  3.73957008e-02,\n",
       "           9.73109454e-02, -2.65465751e-02, -5.26166372e-02,\n",
       "          -4.15529162e-02,  1.27851263e-01, -6.90419897e-02,\n",
       "          -1.03692971e-02,  8.64877775e-02, -5.44591732e-02,\n",
       "          -9.19745583e-03, -5.61584644e-02,  4.41987179e-02,\n",
       "           5.17806895e-02,  5.70727848e-02, -7.05628656e-03,\n",
       "           1.28760546e-01, -5.06147407e-02,  7.52017877e-05,\n",
       "          -9.55295004e-03,  5.40642515e-02,  1.00255720e-01,\n",
       "          -1.86083224e-02, -2.41076220e-02, -7.83717856e-02,\n",
       "          -4.94133346e-02,  1.37130078e-02, -1.94596183e-02,\n",
       "          -1.22561477e-01, -2.78481306e-03,  1.48887888e-01,\n",
       "           6.17874190e-02, -8.66510421e-02,  6.71465993e-02,\n",
       "           1.04003869e-01, -3.02544776e-02, -2.75619421e-02,\n",
       "          -6.76512420e-02, -5.16655892e-02,  9.09735411e-02,\n",
       "          -5.55237271e-02,  9.31795500e-03, -1.03813216e-01,\n",
       "          -6.78035170e-02, -4.90732584e-03, -3.99303697e-02,\n",
       "          -8.85709189e-03,  1.57583848e-01,  1.86782554e-02,\n",
       "          -1.61503479e-01, -6.97395653e-02,  2.98497221e-03,\n",
       "           1.45129442e-01, -1.98898502e-02,  2.77316719e-02,\n",
       "          -4.86556441e-02, -1.24414228e-01, -5.66075593e-02,\n",
       "          -1.04652010e-01, -7.86075965e-02,  1.30798697e-01,\n",
       "          -1.08073261e-02, -1.13410028e-02,  2.82882713e-02,\n",
       "          -1.38796745e-02,  3.94997299e-02,  9.32651311e-02,\n",
       "           9.50753912e-02, -9.57379863e-02, -5.08618802e-02,\n",
       "           9.74370092e-02, -1.28823426e-02,  9.39668119e-02,\n",
       "          -3.67642310e-03,  8.52015987e-02,  1.11433983e-01,\n",
       "           1.49949240e-02,  1.18683934e-01, -7.82573447e-02,\n",
       "           1.77485179e-02, -2.79827379e-02, -4.23678830e-02,\n",
       "          -7.61210993e-02, -6.08765520e-02,  1.23052433e-01,\n",
       "          -6.83869049e-02, -1.13795795e-01, -4.15131114e-02,\n",
       "          -9.56135839e-02,  7.00249057e-03,  1.62090629e-01,\n",
       "           2.09197387e-01, -5.48365153e-02,  4.76328954e-02,\n",
       "          -5.77630997e-02, -4.82741855e-02, -3.25090811e-02,\n",
       "           2.15921476e-01, -3.30875963e-02, -1.08709715e-01,\n",
       "           8.88644606e-02,  2.14795284e-02, -3.97705883e-02,\n",
       "          -1.51340872e-01, -2.33969651e-02,  2.12327652e-02,\n",
       "           7.47947767e-02, -4.39547934e-03, -1.51787186e-04,\n",
       "          -2.16572862e-02, -1.05332963e-01, -3.62371020e-02,\n",
       "          -9.90918130e-02, -1.25505924e-01, -2.81533487e-02,\n",
       "           2.57253908e-02,  1.49913564e-01,  3.18027288e-02,\n",
       "           5.49649820e-02,  5.08860946e-02, -5.35541549e-02,\n",
       "           3.95918451e-02, -1.69910230e-02,  1.61995009e-01,\n",
       "           3.64901163e-02, -1.60496756e-02,  4.71362360e-02,\n",
       "          -1.29187154e-02, -3.84549275e-02, -6.19043112e-02,\n",
       "           5.25622368e-02,  5.22340685e-02,  6.02927320e-02,\n",
       "          -3.10959350e-02, -1.49206975e-02,  1.28776394e-02,\n",
       "          -1.52112707e-01, -8.32829848e-02,  3.22895609e-02,\n",
       "           3.66810081e-03,  7.67797828e-02, -8.72124657e-02,\n",
       "          -8.88054594e-02, -3.30627110e-04,  6.59849793e-02,\n",
       "           1.00656077e-02, -3.93699445e-02, -7.54807368e-02,\n",
       "           6.00696094e-02, -1.10136904e-01,  5.61585166e-02,\n",
       "          -3.74350660e-02, -1.81745812e-02,  9.84257907e-02,\n",
       "           3.57949622e-02, -4.78287116e-02, -6.31948784e-02,\n",
       "           5.32683022e-02, -1.55138567e-01,  7.68464059e-02,\n",
       "          -9.53961462e-02,  1.71967745e-01,  2.46956516e-02,\n",
       "          -4.42485288e-02, -7.57133961e-02, -7.93061629e-02,\n",
       "          -1.17532827e-01, -1.19029582e-02, -2.76216469e-03,\n",
       "           1.05108097e-01,  6.22617118e-02, -5.68789430e-02,\n",
       "          -1.09074473e-01,  8.48790109e-02,  2.20959812e-01,\n",
       "          -1.14749372e-01, -7.34425858e-02, -2.97492631e-02,\n",
       "           2.28459835e-02, -4.44279611e-02, -2.58146226e-02,\n",
       "          -6.85995221e-02,  2.29216255e-02,  1.07538901e-01,\n",
       "           6.90508559e-02,  2.05102209e-02, -9.59405452e-02,\n",
       "           1.96400527e-02,  1.09102935e-01, -4.27073911e-02,\n",
       "           1.11773960e-01,  1.02007836e-01, -8.05005804e-02,\n",
       "          -8.72937590e-02,  1.23298317e-01,  4.17192243e-02,\n",
       "           4.89924811e-02,  7.49343038e-02,  1.46792337e-01,\n",
       "           7.87148327e-02, -2.41293013e-02, -1.96338132e-01,\n",
       "          -9.92436800e-03,  5.64342132e-03,  7.40138069e-02,\n",
       "           4.84968312e-02,  7.24647716e-02,  6.61712065e-02,\n",
       "           4.34850715e-02, -7.00513422e-02,  8.39965977e-03,\n",
       "           4.26338464e-02, -1.85878817e-02,  8.58523510e-03,\n",
       "           6.69061989e-02,  1.36190847e-01, -2.00533904e-02,\n",
       "           1.00267015e-01, -5.28676361e-02, -3.24591510e-02,\n",
       "           6.58783466e-02, -5.36304712e-02, -1.24904749e-04,\n",
       "          -9.49237719e-02,  1.12168081e-01,  1.22879468e-01,\n",
       "          -8.01838785e-02, -1.21610001e-01,  4.43546213e-02,\n",
       "           1.02523357e-01, -3.70555259e-02, -1.83258399e-01,\n",
       "           8.64064787e-03, -1.39290050e-01,  1.97690278e-02,\n",
       "          -1.82441529e-02, -5.32140620e-02,  3.11814416e-02,\n",
       "           4.20267582e-02, -6.74689189e-02,  2.73153167e-02,\n",
       "           6.54269569e-03, -7.80932084e-02,  9.78526250e-02,\n",
       "           1.11889318e-02, -3.92399281e-02,  1.78141277e-02,\n",
       "           1.23421960e-02,  7.58464932e-02,  1.20893970e-01,\n",
       "          -1.28325261e-02, -9.07417759e-02, -1.66321732e-02,\n",
       "          -1.26416102e-01,  5.21450453e-02,  5.80312759e-02,\n",
       "          -4.50751558e-02, -3.69270071e-02,  1.40049774e-02,\n",
       "           6.44917637e-02,  1.06402129e-01, -8.48266110e-03,\n",
       "          -5.04958164e-03, -2.49440931e-02, -1.07630854e-02,\n",
       "           9.08160210e-02,  3.66884694e-02, -4.02741693e-02,\n",
       "           7.93914124e-02, -9.48458388e-02, -4.40191142e-02,\n",
       "           1.25457691e-02,  5.95330186e-02,  1.24735154e-01,\n",
       "          -5.87037392e-02,  2.52595484e-01, -9.44618657e-02,\n",
       "          -6.64543584e-02,  8.54264852e-03, -1.51200872e-02,\n",
       "           1.15441523e-01, -9.42625031e-02, -8.52248520e-02,\n",
       "          -1.23027965e-01,  2.95410841e-03, -2.13089824e-01,\n",
       "          -4.27649766e-02,  8.53963941e-03, -5.34814643e-03,\n",
       "          -3.20280641e-02, -1.00485869e-01,  2.03682780e-02,\n",
       "          -5.90564087e-02, -3.77070233e-02,  6.73484728e-02,\n",
       "          -1.23375962e-02,  5.45578972e-02,  2.66903993e-02,\n",
       "           1.88927557e-02,  7.77114183e-02, -4.86916788e-02,\n",
       "           5.49590923e-02, -1.87748168e-02, -9.00398009e-03,\n",
       "          -9.19249356e-02, -4.25311998e-02,  1.22127868e-02,\n",
       "           1.82260409e-01, -8.50776061e-02,  7.38913119e-02,\n",
       "          -6.57753497e-02,  1.07591473e-01, -6.25610575e-02,\n",
       "          -1.24533828e-02,  6.74573928e-02,  9.94401500e-02,\n",
       "           6.04331866e-02, -1.29511982e-01,  6.52642827e-03,\n",
       "          -6.93439096e-02,  1.71786055e-01, -3.48462313e-02,\n",
       "          -1.63389325e-01, -7.12170154e-02,  5.43733640e-03,\n",
       "           1.46758303e-01, -1.09455645e-01,  1.06502861e-01,\n",
       "           1.40747903e-02,  1.32390589e-01,  9.48971603e-03,\n",
       "           1.92879274e-01,  3.92592102e-02,  5.62026165e-02,\n",
       "           6.67029098e-02, -9.12800357e-02, -5.47230653e-02,\n",
       "          -7.11299330e-02,  1.90075561e-02, -2.61555333e-03,\n",
       "           1.05791785e-01,  3.31501886e-02,  4.94979508e-02,\n",
       "           1.63662024e-02,  1.07913353e-01,  2.75941864e-02,\n",
       "           6.11829245e-03, -8.62052478e-03, -1.91370193e-02,\n",
       "          -4.01439816e-02,  1.75447464e-01, -6.67436346e-02,\n",
       "          -1.13768183e-01, -9.03040171e-03,  4.26808782e-02,\n",
       "           5.06278649e-02,  6.95307367e-03, -7.92805105e-02,\n",
       "           1.37253433e-01, -7.66587108e-02, -3.98769304e-02,\n",
       "          -8.30681399e-02,  5.21376953e-02,  1.92365646e-02,\n",
       "           2.27530655e-02,  4.70287129e-02,  8.56149048e-02,\n",
       "           1.28934503e-01,  7.67025426e-02, -6.73610857e-03,\n",
       "           7.97354281e-02, -2.80271638e-02,  3.49922441e-02,\n",
       "           7.70625984e-03, -1.91226660e-03, -5.65892868e-02,\n",
       "           1.37748465e-01, -1.62468091e-01, -6.77884743e-02,\n",
       "           6.25544116e-02, -1.88184679e-02, -3.69981118e-02,\n",
       "          -1.22216478e-01, -7.87430257e-03, -1.00455627e-01,\n",
       "           9.11819264e-02, -1.58199538e-02, -8.91876817e-02,\n",
       "          -7.67345056e-02,  2.03561392e-02,  7.66077312e-03,\n",
       "           5.15325144e-02,  2.24873256e-02,  3.76444533e-02,\n",
       "           1.69609308e-01,  1.55367097e-02, -1.30078420e-01,\n",
       "          -6.24521077e-02, -4.90061939e-02, -3.39586064e-02,\n",
       "          -8.22992697e-02, -1.17402235e-02,  5.24621047e-02,\n",
       "           3.87473926e-02, -4.05511484e-02,  2.06238955e-01,\n",
       "           3.17047387e-02,  5.02803884e-02, -4.05611144e-03,\n",
       "          -1.77548155e-02,  9.75668523e-03, -8.00967291e-02,\n",
       "           5.36879301e-02, -5.39286993e-02,  9.81010124e-02,\n",
       "           6.65797070e-02,  5.96772470e-02, -3.10548469e-02,\n",
       "           2.18690604e-01,  3.43974046e-02,  1.87357645e-02,\n",
       "           1.32977679e-01, -6.19884953e-03,  1.38109863e-01,\n",
       "           4.54287231e-02, -5.19495718e-02, -6.89318106e-02,\n",
       "           2.09672377e-01,  2.42888811e-03, -4.34259549e-02,\n",
       "           6.44775927e-02,  4.16690409e-02,  1.00912964e-02,\n",
       "          -4.41864878e-02, -4.79109772e-02,  1.33300135e-02,\n",
       "          -5.27306199e-02, -7.85162374e-02,  3.27407904e-02,\n",
       "          -1.17383800e-01, -8.12179893e-02,  7.29676932e-02,\n",
       "           2.40877215e-02,  1.36905998e-01, -8.09516013e-02,\n",
       "          -1.19778351e-03, -8.03079978e-02]], dtype=float32)],\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_batch(dataset, target_dim, batch_size=64):\n",
    "    batch_idx = 0\n",
    "    entity_map = kb_mgr.entity_map\n",
    "    \n",
    "    remainder = len(dataset) % batch_size\n",
    "    if remainder != 0:\n",
    "        dataset = dataset[:-remainder]\n",
    "        \n",
    "    while batch_idx < len(dataset):\n",
    "        batch = dataset[batch_idx:batch_idx+batch_size]\n",
    "        \n",
    "        qs = list(map(lambda qa: qa.question, batch))\n",
    "        tokens = tokenizer(\n",
    "            qs,\n",
    "            return_tensors=\"tf\",\n",
    "            padding=True\n",
    "        )\n",
    "        \n",
    "        q_embedds = q_embedder(tokens)\n",
    "        q_embedds = q_embedds[0].numpy()[:, 0, :]\n",
    "        \n",
    "        entities = map(lambda qa: qa.question_entity, batch)\n",
    "        entity_ids = list(map(lambda e: entity_map[e], entities))\n",
    "        entity_embedds = kg_model.entity_encoder(np.array(entity_ids)).numpy()\n",
    "        \n",
    "        labels_list = map(lambda qa: qa.answers, batch)\n",
    "        \n",
    "        Xs = [q_embedds, entity_embedds]\n",
    "        Ys = np.zeros((batch_size, target_dim))\n",
    "        for idx, labels in enumerate(labels_list):\n",
    "            targets = list(map(lambda ans: entity_map[ans], labels))\n",
    "            Ys[idx][targets] = 1\n",
    "        \n",
    "        yield Xs, Ys\n",
    "        batch_idx += batch_size\n",
    "                    \n",
    "next(iter(get_batch(\n",
    "    [QA(\n",
    "        question='hey Kismet',\n",
    "        question_entity='Kismet',\n",
    "        answers=['James Bradley']\n",
    "    )],\n",
    "    target_dim=20,\n",
    "    batch_size=1)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0817 21:02:43.413469 140365751764800 base_layer.py:1790] Layer embed_kgqa is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0817 21:02:43.424565 140365751764800 base_layer.py:1790] Layer batch_normalization_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embed_kgqa\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  393728    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  262656    \n",
      "_________________________________________________________________\n",
      "kbg_model_1 (KBGModel)       multiple                  22141448  \n",
      "=================================================================\n",
      "Total params: 23,060,488\n",
      "Trainable params: 919,040\n",
      "Non-trainable params: 22,141,448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class EmbedKGQA(keras.Model):\n",
    "    def __init__(self, graph_embedding_model):\n",
    "        super(EmbedKGQA, self).__init__()\n",
    "        self.fc1 = keras.layers.Dense(512, input_shape=(768,))\n",
    "        self.fc2 = keras.layers.Dense(512)\n",
    "        self.fc3 = keras.layers.Dense(512)\n",
    "        self.graph_embedding_model = graph_embedding_model\n",
    "        self.graph_embedding_model.trainable = False\n",
    "    \n",
    "    \n",
    "    def call(self, q_embeddings, q_entity_embeddings):\n",
    "        question_complex = self.fc1(q_embeddings)\n",
    "        question_complex = self.fc2(question_complex)\n",
    "        question_complex = self.fc3(question_complex)\n",
    "        \n",
    "        scores = self.graph_embedding_model.get_score(\n",
    "            q_entity_embeddings,\n",
    "            question_complex,\n",
    "            self.graph_embedding_model.entity_encoder\n",
    "        )\n",
    "        \n",
    "        prediction = tf.sigmoid(scores)\n",
    "        return prediction\n",
    "        \n",
    "    \n",
    "embedKGQA = EmbedKGQA(kg_model)\n",
    "\n",
    "embedKGQA(\n",
    "    np.ones((10, 768)),\n",
    "    np.ones((10, 512)),\n",
    "    training=False\n",
    ")\n",
    "\n",
    "embedKGQA.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = keras.metrics.Mean(name='train_loss')\n",
    "validation_loss = keras.metrics.Mean(name='validation_loss')\n",
    "\n",
    "@tf.function\n",
    "def train_step(q_embeddings, q_entity_embeddings, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = embedKGQA(\n",
    "            q_embeddings,\n",
    "            q_entity_embeddings,\n",
    "            training=True\n",
    "        )\n",
    "        loss = loss_fn(y_true=targets, y_pred=predictions)\n",
    "    grads = tape.gradient(loss, embedKGQA.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, embedKGQA.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    \n",
    "@tf.function\n",
    "def validation_step(q_embeddings, q_entity_embeddings, targets):\n",
    "    predictions = embedKGQA(\n",
    "        q_embeddings,\n",
    "        q_entity_embeddings,\n",
    "        training=False\n",
    "    )\n",
    "    loss = loss_fn(y_true=targets, y_pred=predictions)\n",
    "    validation_loss(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "VALIDATION_BATCH_SIZE = 2048\n",
    "TRAIN_LOG_STEP = 20\n",
    "entity_dim = len(kb_mgr.entity_map)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss.reset_states()\n",
    "    validation_loss.reset_states()\n",
    "    \n",
    "    iteration = 0\n",
    "    for x, y in get_batch(train_dataset, entity_dim, batch_size=BATCH_SIZE):\n",
    "        train_step(x[0], x[1], y)\n",
    "        \n",
    "        if not iteration % TRAIN_LOG_STEP:\n",
    "            print('training loss in iteration {}: {}'.format(iteration, train_loss.result()))\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "    for x, y in get_batch(valid_dataset, entity_dim, batch_size=VALIDATION_BATCH_SIZE):\n",
    "        validation_step(x[0], x[1], y)\n",
    "    \n",
    "    print(\"epoch:{} validation_loss:{}\".format(epoch, validation_loss.result()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embed_kgqa\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  393728    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  262656    \n",
      "_________________________________________________________________\n",
      "kbg_model_1 (KBGModel)       multiple                  22141448  \n",
      "=================================================================\n",
      "Total params: 23,060,488\n",
      "Trainable params: 919,040\n",
      "Non-trainable params: 22,141,448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedKGQA.load_weights('data/saved_models/embedkgqa')\n",
    "embedKGQA.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: what words describe film The Illusionist\n",
      "answers: ['magic', 'edward norton', 'paul giamatti', 'jessica biel', 'vienna', 'neil burger']\n",
      "question: the movie Herbie Goes Bananas starred who\n",
      "answers: ['Cloris Leachman']\n",
      "model answer: ['jessica biel' 'edward norton' 'vienna' 'neil burger' 'sylvain chomet']\n",
      "true answer: ['jessica biel' 'magic' 'paul giamatti' 'edward norton' 'vienna'\n",
      " 'neil burger']\n",
      "model answer: ['Cloris Leachman']\n",
      "true answer: ['Cloris Leachman']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "thr = 0.05\n",
    "\n",
    "keys = np.array(list(kb_mgr.entity_map.keys()))\n",
    "idx = random.randint(1, len(test_dataset)-2)\n",
    "qa1, qa2 = test_dataset[idx], test_dataset[idx+1]\n",
    "\n",
    "print(\"question: {}\\nanswers: {}\".format(qa1.question, qa1.answers))\n",
    "print(\"question: {}\\nanswers: {}\".format(qa2.question, qa2.answers))\n",
    "\n",
    "x, y = next(iter(get_batch(\n",
    "    [qa1, qa2],\n",
    "    target_dim=entity_dim,\n",
    "    batch_size=2)\n",
    "))\n",
    "\n",
    "preds = embedKGQA(\n",
    "    x[0],\n",
    "    x[1],\n",
    "    training=False\n",
    ").numpy()\n",
    "\n",
    "preds_idxs = np.where(preds >= thr, 1.0, 0.0).astype('bool')\n",
    "y = y.astype('bool')\n",
    "\n",
    "np.sum(preds_idxs), np.sum(y)\n",
    "for i, pred_idx in enumerate(preds_idxs):\n",
    "    pred = keys[pred_idx]\n",
    "    print(\"model answer: {}\".format(pred))\n",
    "    label = keys[y[i]]\n",
    "    print(\"true answer: {}\".format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"answers include our prediction\" accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "1it [00:03,  3.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "2it [00:06,  3.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "3it [00:09,  3.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "4it [00:12,  3.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "5it [00:16,  3.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [00:19,  3.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "7it [00:22,  3.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "8it [00:25,  3.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "9it [00:28,  3.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "10it [00:32,  3.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "11it [00:35,  3.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "12it [00:38,  3.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "13it [00:41,  3.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "14it [00:44,  3.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "15it [00:48,  3.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "16it [00:51,  3.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "17it [00:54,  3.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "18it [00:57,  3.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "19it [01:00,  3.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "20it [01:03,  3.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "21it [01:06,  3.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "22it [01:09,  3.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "23it [01:13,  3.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "24it [01:16,  3.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "25it [01:19,  3.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "26it [01:22,  3.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "27it [01:25,  3.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "28it [01:28,  3.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "29it [01:31,  2.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "30it [01:34,  3.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "31it [01:37,  3.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "32it [01:40,  3.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "33it [01:44,  3.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "34it [01:47,  3.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "35it [01:49,  3.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "36it [01:52,  3.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "37it [01:55,  2.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "38it [01:58,  2.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "39it [02:01,  3.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "40it [02:05,  3.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "41it [02:08,  3.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "42it [02:12,  3.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "43it [02:15,  3.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "44it [02:18,  3.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "45it [02:22,  3.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "46it [02:26,  3.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "47it [02:30,  3.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "48it [02:33,  3.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "49it [02:37,  3.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "50it [02:40,  3.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "51it [02:44,  3.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "52it [02:47,  3.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "53it [02:51,  3.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "54it [02:54,  3.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "55it [02:57,  3.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "56it [03:00,  3.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "57it [03:04,  3.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "58it [03:08,  3.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "59it [03:11,  3.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "60it [03:14,  3.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "61it [03:17,  3.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "62it [03:21,  3.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "63it [03:24,  3.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "64it [03:28,  3.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "65it [03:31,  3.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "66it [03:35,  3.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "67it [03:39,  3.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "68it [03:43,  3.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "69it [03:47,  3.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "70it [03:50,  3.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "71it [03:54,  3.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "72it [03:57,  3.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "73it [04:00,  3.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "74it [04:03,  3.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "75it [04:07,  3.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-af57021dbffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-eb1bdce3f7f0>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(dataset, target_dim, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m         )\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mq_embedds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_embedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mq_embedds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_embedds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/transformers/modeling_tf_roberta.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mheads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \"\"\"\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroberta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/transformers/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, training)\u001b[0m\n\u001b[1;32m    607\u001b[0m         encoder_outputs = self.encoder(\n\u001b[1;32m    608\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m         )\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/transformers/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             layer_outputs = layer_module(\n\u001b[0;32m--> 399\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m             )\n\u001b[1;32m    401\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/transformers/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         attention_outputs = self.attention(\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m         )\n\u001b[1;32m    377\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/transformers/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         self_outputs = self.self_attention(\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         )\n\u001b[1;32m    324\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/transformers/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mmixed_query_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mmixed_key_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mmixed_value_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0;31m# Broadcasting is required for the inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m       \u001b[0;31m# Reshape the output back to the original ndim of the input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes, name)\u001b[0m\n\u001b[1;32m   4104\u001b[0m     b_reshape, b_free_dims, b_free_dims_static = _tensordot_reshape(\n\u001b[1;32m   4105\u001b[0m         b, b_axes, True)\n\u001b[0;32m-> 4106\u001b[0;31m     \u001b[0mab_matmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_reshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4108\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mab_matmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_free_dims\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2796\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2797\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2798\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5604\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5605\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5606\u001b[0;31m         transpose_b)\n\u001b[0m\u001b[1;32m   5607\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5608\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "hits = 0\n",
    "total = 0\n",
    "batch_size = 100\n",
    "\n",
    "for x, y in tqdm(get_batch(test_dataset, entity_dim, batch_size=batch_size)):\n",
    "    total += batch_size\n",
    "    \n",
    "    predictions = embedKGQA(\n",
    "        x[0],\n",
    "        x[1],\n",
    "        training=False\n",
    "    )\n",
    "    \n",
    "    best_guess = np.argmax(predictions, axis=1)\n",
    "    y = np.argpartition(y, -k)[:, -k:]\n",
    "    for idx, guess in enumerate(best_guess):\n",
    "        if guess in y[idx]:\n",
    "            hits += 1\n",
    "    \n",
    "    print('accuracy: {:.2f}'.format(hits/total))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1it [00:02,  2.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2it [00:04,  2.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3it [00:06,  2.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4it [00:08,  2.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5it [00:10,  2.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [00:12,  2.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.56\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-6814050e5754>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-eb1bdce3f7f0>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(dataset, target_dim, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m         )\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mq_embedds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_embedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mq_embedds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_embedds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/transformers/modeling_tf_roberta.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mheads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \"\"\"\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroberta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/transformers/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, training)\u001b[0m\n\u001b[1;32m    607\u001b[0m         encoder_outputs = self.encoder(\n\u001b[1;32m    608\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m         )\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/transformers/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             layer_outputs = layer_module(\n\u001b[0;32m--> 399\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m             )\n\u001b[1;32m    401\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/transformers/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         attention_outputs = self.attention(\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m         )\n\u001b[1;32m    377\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/transformers/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         )\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/transformers/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0;31m# Broadcasting is required for the inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m       \u001b[0;31m# Reshape the output back to the original ndim of the input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes, name)\u001b[0m\n\u001b[1;32m   4104\u001b[0m     b_reshape, b_free_dims, b_free_dims_static = _tensordot_reshape(\n\u001b[1;32m   4105\u001b[0m         b, b_axes, True)\n\u001b[0;32m-> 4106\u001b[0;31m     \u001b[0mab_matmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_reshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4108\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mab_matmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_free_dims\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2796\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2797\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2798\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2env/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5604\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5605\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5606\u001b[0;31m         transpose_b)\n\u001b[0m\u001b[1;32m   5607\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5608\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "hits = 0\n",
    "total = 0\n",
    "batch_size = 100\n",
    "threshold = 0.05\n",
    "\n",
    "for x, y in tqdm(get_batch(test_dataset, entity_dim, batch_size=batch_size)):\n",
    "    total += batch_size\n",
    "    \n",
    "    predictions = embedKGQA(\n",
    "        x[0],\n",
    "        x[1],\n",
    "        training=False\n",
    "    )\n",
    "    \n",
    "    preds_idxs = np.where(predictions >= thr, 1.0, 0.0).astype('int')\n",
    "    for idx, guess in enumerate(preds_idxs):\n",
    "        if np.array_equal(guess, y[idx]):\n",
    "            hits += 1\n",
    "    \n",
    "    print('accuracy: {:.2f}'.format(hits/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
